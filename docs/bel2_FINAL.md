

T.C.
İSTANBUL OKAN ÜNİVERSİTESİ
LİSANSÜSTÜ EĞİTİM ENSTİTÜSÜ



YÜKSEK LİSANS TEZİ
BİLİŞİM SİSTEMLERİ ANABİLİM DALI

Ersin ARIKAN
YAPAY ZEKA DESTEKLİ GÖRSEL ve VİDEO İÇERİK ANALİZİ: TOPLUMSAL DEĞERLERİN KORUNMASI İÇİN ÖĞRENEN BİR UYGULAMA



DANIŞMAN
Dr. Öğr. Üyesi Ender ŞAHİNASLAN




İSTANBUL, Aralık 2025
İÇİNDEKİLER
ÖNSÖZ	4
ÖZET	5
SUMMARY	6
KISALTMALAR	8
ŞEKİL LİSTESİ	9
TABLO LİSTESİ	10
BÖLÜM 1 GİRİŞ ve AMAÇ	11
1.1.	PROBLEM TANIMI ve MOTİVASYON	11
1.2.	TEZİN AMACI ve HEDEFLER	11
1.3.	KAPSAM ve KATKILAR	12
1.4.	PROJE GELİŞTİRME SÜRECİ ve ZAMAN ÇİZELGESİ	13
BÖLÜM 2 GENEL BİLGİLER VE LİTERATÜR	15
2.1. BİLGİSAYARLI GÖRÜ ve İÇERİK ANALİZİ TEMELLERİ	15
2.2. TRANSFER/ARTIMSAL ÖĞRENME YAKLAŞIMLARI	16
2.3. VERİ KALİTESİ ve GÜVEN SKORLAMA	18
2.4. UYGULAMA ODAKLI ÇALIŞMALAR ve BOŞLUK ANALİZİ	20
2.5. İÇERİK MODERASYONU ve ÇOK MODELLİ YAKLAŞIMLAR	22
BÖLÜM 3 SİSTEM ve MİMARİ	24
3.1. GENEL MİMARİ	24
3.2. UYGULAMA YAŞAM DÖNGÜSÜ	24
3.3. KONFİGÜRASYON SABİTLER, DURUM ve YOL HİYERARŞİSİ	25
3.4. GÜNCELLENEBİLİR ANALİZ PARAMETRELERİ ve MODEL DURUMU	26
3.5. VARLIK İLİŞKİ MODELİ ve DOSYA YÖNETİMİ	27
3.6. PLAFORM, UYGULAMA YAYINLAMA KATMANI	29




ÖNSÖZ
Bu çalışma, kurum içi gereksinimlerden doğan gerçek bir yazılım ürününün araştırma ve geliştirme sürecine dayanır. Geliştirme boyunca kararların teknik ve kurumsal dayanakları dikkatle belgelenmiş, her adımda etik, güvenlik ve gizlilik ilkeleri gözetilmiştir. 
Bu sürece katkı veren tüm meslektaşlarıma ve değerli danışmanım Dr. Öğr. Üyesi Ender Şahinaslan'a teşekkürlerimi ve saygılarımı sunarım.


Ersin ARIKAN
İSTANBUL, 2025



ÖZET
YAPAY ZEKA DESTEKLİ GÖRSEL ve VİDEO İÇERİK ANALİZİ: TOPLUMSAL DEĞERLERİN KORUNMASI İÇİN ÖĞRENEN BİR UYGULAMA
Bu tezde, yüksek hacimli görsel ve video içeriğini anlamak ve kurumsal değerlendirme kriterleri için içeriği otomatik ve yarı otomatik olarak analiz etmeyi amaçlayan bir yazılım sistemi geliştirilmiştir. Sistem, sosyal medya, televizyon yayınları ve çeşitli internet kaynaklarından elde edilen içeriğin, çocukların zihinsel gelişimi ve toplumun ahlaki değerleri üzerindeki risklerini standart bir şekilde hızlı ve tutarlı bir şekilde tanımlamayı hedeflemektedir. Uygulama, içeriği sınıflandırmak için OpenCLIP'i, nesne/kişiyi tespit etmek için YOLO'yu, yüz analizi için ise InsightFace'i entegre eden bir Python arka uç mimarisine dayanmaktadır. Depolama, kuyruklama, gerçek zamanlı bildirimler ve diğer alt sistemlerin yapılandırması, üretim ortamına uygun ölçeklenebilir, yeniden başlatılabilir ve operasyonel olarak kontrol edilen bir iş akışını destekleyecek şekilde tasarlanmıştır. Sistem tasarımının ayırt edici özelliği, uzmanlardan alınan geri bildirimler ve yüksek güvenilirlikteki sahte etiketler kullanılarak artımlı öğrenme döngülerinin kapatılmasıdır. Bu amaçla, metin-görüntü tabanlı anlamsal doğrulamayı, birden fazla modelde güvenilir çapraz model çıktı tutarlılığı ile entegre eden bir güven puanı yöntemi önerilmektedir. Bu, OpenCLIP tarafından üretilen olumlu/olumsuz isteme dayalı benzerlik metrikleri ve iki model arasındaki tahminlerin yakınlığını dikkate alarak yapılmaktadır. Bu şekilde, gürültülü akışlarla zayıf denetimli çerçeveler, hızlı artımlı güncellemelere olanak tanıyarak kullanılabilir hale gelmektedir. Bu, rafine kriterlere dayanan bir analiz için güvenilir bir alt kümenin ortaya çıkmasıyla gerçekleştirilmiştir.
Çalışmanın ön denemeleri için, sapma ±5 yıl olmak üzere, doğruluk, MAE/MSE ve işlem süresi gibi ölçütlerle yapılan değerlendirmeler, hafif başlıkların, yüksek güvenli altkümelerle eğitildiği dönemde, tüm verilere göre eğitime daha kısa sürede, daha tutarlı sonuçlar verdiğini göstermektedir. Mimari, kuruma-gereksinim (on-premises) dağıtım ve veri gizliliği gereksinimlerini karşıladığından, uygulama değerini, üretim koşullarında, sürdürülebilir sürümleme ve geri dönüş (rollback) süreçleri ile birlikte, yanıt verme ölçüte eklemektedir. Yine, bu çalışma, içerik değerlendirmede, tutarlılığı artıran, zaman kazancı sağlayan ve insan yükünü azaltan bir arka uç çözümü sunduğunu belirtmektedir. Tüm bunlar, Türkçe bağlama özgü davranış farklılıklarını dikkate alan yerelleştirme olanakları ile birlikte, çalışmanın, literatürdeki boşluklara katkı sunduğunu göstermektedir.




Anahtar Kelimeler: Görsel içerik analizi, OpenCLIP, InsightFace, artımsal öğrenme, güven skoru, Socket.IO, Python, Flask
Tarih: Aralık 2025

SUMMARY
ARTIFICIAL INTELLIGENCE-SUPPORTED VISUAL AND VIDEO CONTENT ANALYSIS: A LEARNING APPLICATION FOR THE PROTECTION OF SOCIAL VALUES
In this thesis, a software system is developed to understand high-volume visual and video content and analyze it automatically and semi-automatically for institutional evaluation criteria. The system aims to quickly and consistently identify the risks of content obtained from social media, television broadcasts, and various internet sources on children's cognitive development and society's moral values ​​in a standardized manner. The application is based on a Python backend architecture that integrates OpenCLIP for content classification, YOLO for object/person detection, and InsightFace for face analysis. The configuration of storage, queuing, real-time notifications, and other subsystems is designed to support a scalable, replayable, and operationally controlled workflow suitable for production environments. A distinguishing feature of the system design is the closure of incremental learning loops using expert feedback and high-confidence pseudo-labels. To this end, a confidence score method is proposed that integrates text-image-based semantic verification with reliable cross-model output consistency across multiple models. This is achieved by considering similarity metrics based on positive/negative claims generated by OpenCLIP and the closeness of predictions between the two models. This allows for rapid incremental updates to noisy streams, making weakly supervised frameworks usable. This has been achieved by creating a reliable subset for analysis based on refined criteria.
Evaluations of metrics such as accuracy, MAE/MSE, and processing time, with a ±5-year deviation for preliminary tests, indicate that lightweight titles, when trained with high-confidence subsets, yield more consistent results in a shorter training time than the entire dataset. Because the architecture meets on-premises deployment and data privacy requirements, it adds responsiveness to the metric, along with sustainable versioning and rollback processes under production conditions. Furthermore, this study demonstrates that it offers a back-end solution for content evaluation that increases consistency, saves time, and reduces human overhead. All of this, along with localization capabilities that address behavioral differences specific to the Turkish context, demonstrates that the study contributes to gaps in the literature.


Keywords: Visual content analysis, OpenCLIP, InsightFace, incremental learning, confidence scoring, Socket.IO, Python, Flask
Date: December 2025

SEMBOLLER



KISALTMALAR
API: Application Programming Interface  
MAE: Mean Absolute Error  
MSE: Mean Squared Error  
ROC: Receiver Operating Characteristic  
REST: Representational State Transfer



ŞEKİL LİSTESİ
Şekil 1.2. Proje Takvimi	14
Şekil 3.5. Veri Tabanı ER Diyagramı	28



TABLO LİSTESİ



BÖLÜM 1 GİRİŞ ve AMAÇ
 PROBLEM TANIMI ve MOTİVASYON
Son 20-25 yıl içinde dijital içerik üretiminin miktar ve çeşitlilik bakımından büyüyünce, bu alanda düzenleyici ve denetleyici yetkisi bulunan kamu otoritelerine (RTÜK, BTK, Aile ve Sosyal Hizmetler Bakanlığı vb.) yeni görev ve sorumluluklar da eklenmiştir. Bu durum, daha çok görsel ve video tabanlı içeriklerin toplumsal değerlere, hukuka ve kurumsal normlara uygun olup olmadığının, belirli eksenler ve standart yöntemlerle, nicelik ve nitelik kriterleri içinde, kapsamlı ve sistematik olarak, değerlendirilmesi gereğini doğurmuştur. Nitelik ölçütlerine odaklanarak sınırları belirlenemeyen ve sistematik olmayan mevcut uygulamalarda ise, özellikle televizyon, sosyal medya ve diğer çevrimiçi platformlardan yayımlanan içeriklerin yoğun akışı, “güvenli”, “zararlı”, “yetişkin”, “şiddet”, “silah”, “istismar” ve “madde kullanımı” gibi kategorilerde sınıflandırılması gerekliliğini göz ardı etmiştir. Özellikle uzman görüşlerine dayanarak değerlendirilen şiddet içerikli yayınlar ve çocuk istismarı gibi hassas içeriklerde yoğun içerik akışı nedeniyle sınıflandırmalarda büyük tutarsızlıklar gözlemlenmektedir. Bu durum, standart, sürekli ve daha otomatikleştirilmiş yöntemlerin ve yeni sınıflama metodolojilerinin geliştirilmesi gereğini ortaya koymaktadır.
Bu çalışma kapsamında çok kaynaklı verilerin işlenmesi, sürekli öğrenme işlevine sahip yapay zeka modellerinin entegre edildiği yeni sınıflama metodolojileri, görsel ve video içeriklerin kurumsal nitelik standartlarına uygun biçimde, düzenli ve tutarlı bir biçimde değerlendirilmesini sağlayan yenilikçi bir dijital uygulama olarak kullanımınıza sunulmuştur. Kullanıcı geri bildirimlerinden, Türk Kültürü ve Türk Beden Dili bağlamında etkisinin hareketlerin de yorumlanabileceği bir yapay zeka modeli geliştirildi/geliştirilmektedir, bu suret ile analiz süreleri kısalırken, sınıflama ve içerik analizi nispeten standartlaşmıştır. Analizler sırasında, zararlı içerik tespiti yapılmış video dosyalarında sadece ilgili kısım (2 saniye öncesi, olay ve 2 saniye sonrası) görüntülenmekte, böylece uzmanlar, saatlerce eş zamanlı olarak işleyebilecekleri bir video dosyası ile birden fazla dosya ile eş zamanlı olarak işlemekte. Sistem, Python tabanlı arka uç yazılım ve en son derin öğrenme modelleri (CLIP ve YOLO dahil) üzerine inşa edilmiş bir analiz katmanına sahiptir. Yapay zeka kullanıcı arayüzü, sınırlı yapay zeka okuryazarlığına sahip personel düşünülerek tasarlanmış, otomatik etiketleme ve geri bildirim almaktan uzmanların önerileri onaylamasına, düzeltmesine veya reddetmesine olanak tanımaktadır. Bu veriler, modelin yeniden eğitimi için kullanılarak sistemin doğruluğunu ve tutarlılığını zamanla artırmaktadır. Sistem, bilirkişi veya uzmanların değerlendirme sürelerinde %70’e kadar tasarruf sağlamayı, içerik analizlerinde tutarlılık ve standardizasyon getirmeyi, çalışanların psikososyal yükünü azaltmayı ve değerlendirme süreçlerinin genel kalitesini artırmayı amaçlamaktadır.
TEZİN AMACI ve HEDEFLER
Bu çalışmanın amacı, kurumsal gereksinimlere göre ayarlanabilen, otomatik sistemlerle video ve görsel içeriklerdeki uygunsuz içeriklerin tespit edilmesini sağlayan, üretim ortamında güvenle kullanabilecek ve sürdürülebilir bir sistemin, geliştirilmesi, uygulanması ve etkinliğinin değerlendirilmesidir.
Bu çalışmanın başlangıç aşaması, içerik sınıflandırmasının doğruluğunu artırma amacıyla OpenCLIP prompt tabanlı sıfırdan öğreti tekniklerinin uygulanmasını ve eğitilebilir model başlıklarının (Özel Başlıklar) kullanılmasını, bağlamsal doğrulama ve yanlış pozitiflerin azaltılmasını, YOLO görüntü işleme modeli aracılığıyla sağlanırken, risk kategorileri (şiddet, yetişkin, istismar, silah, ilaç) için ince ayrıntılı puanların üretilmesi,  kullanıcı düzeltmelerinin sisteme anında entegrasyonunu, değerlendirme süreçlerinin optimizasyonunu, artımlı öğrenme yoluyla eğitim sürelerinin azaltılmasını, sistem bakım dönemlerinde kaybı azaltmak için geri dönüş sağlama yeteneği ve sistem sürdürülebilirliğini artırmak için sürümleme ve geri alma mekanizmalarının entegrasyonunu hedeflemiştir.
Bu hedeflere yönelik olarak, kurumsal olarak kullanılabilir bir uygulama geliştirilmiş ve başarıyla üretim ortamında dağıtılmıştır. Sistem, kullanılan çerçeveler, CLIP iş birlikleri ve kişi takiplerine dayalı olarak iş kuyruklarını yönetir, gereksiz hesaplamalardan kaçınır ve değerlendirme döngü süresini optimize eder. Hafif özelliklerle yapılan artımlı güncellemeler, eğitim sürelerini minimize eder ve sürümleme ile geri alma mekanizmaları performans kayıplarını azaltır. Kişi takibindeki otomatik etiketleme mekanizmaları, insan hatalarını minimize eder ve aynı video dosyasında aynı kişi için birden fazla yaş tahminini önler.
Uygulamanın Erişim Güvenliği ve verilerin gizliliği, uygulamanın kritik bileşenleridir. Yerel dağıtımlar ve tutma bileşenleri ile veri sahiplerinin kişisel verileri sistemden çıkmaktan korunur. Dosya yolu ve MIME türü kontrolleri kötü niyetli dosya yüklemelerine karşı koruma sağlar. Hız sınırlaması ve güvenlik başlıkları (CSP, HSTS) siber saldırılara karşı koruma sunar. Tüm bu bileşenler, kurumsal gereksinimlerin (personelin yapay zeka okuryazarlığı, sosyal koruma, sosyal hizmetler ve çocuk koruma yasaları) akademik yöntemlerle entegre edilmesine ve yüksek doğruluk, güvenilirlik ve sürdürülebilirlikle çalışmasına olanak tanır.
Tez kapsamında, örnek uygulama geliştirme kodları da verilmiştir. Uzun vadede, içerik sınıflandırma, güvenlik alanlarında ve bunların ötesinde yapılacak yeni araştırma ve uygulamalar için temel bir model oluşturmasına imkan tanıyacaktır. Bu noktada, transfer ve artımsal öğrenme yöntemleri, güven skorlama teknikleri ve ROC optimizasyonu gibi akademik yöntemlerin sisteme entegrasyonu, sistemin mevcut uygulamalar ve gelecekteki kurumsal projelerde bir referans model olarak kullanılması için bir sistem esnekliği ve sürdürülebilir bir model ilke olarak benimsenmiştir. Sistem özelliği, farklı içerik türleri, risk kategorileri, güvenlik ihtiyaçları ve bu içeriklerin farklı türleri için ileride uyarlanabilir olmasını sağlamak, başlangıç hedefleri arasında bulunmaktadır.
KAPSAM ve KATKILAR
Çalışma, Python tabanlı bir arka uç mimarisinin uçtan uca tasarımını ve uygulanmasını içermektedir. Sistem, OpenCLIP, YOLO ve InsightFace bileşenlerinin entegrasyonu kullanılarak uygulanmıştır. Socket.IO çerçevesi kullanarak, bu bileşenler gerçek zamanlı ilerleme takibi ve sonuçların canlı akışını sağlar. Sonuç olarak, sistem, düşük gecikme süresi ve yüksek doğruluk analizi ile gerçek zamanlı kullanıcı geri bildirimi sağlayan bir üretim kalitesinde çözüme dönüştürülmüştür. Akademik katkıların ana odak noktası, çoklu model güven puanlama, zayıf denetimli öğrenme, çoklu görev içerik ve yaş analizi, kimlik sürekliliği video işleme ve ROC tabanlı güven eşik optimizasyonunu içermektedir. Sistem için önerilen çoklu model güven puanlama, CLIP'in anlamsal doğrulama çıktısını Buffalo-L ve yaş tahmini başlık tahminleri ile birleştirerek zayıf denetimli akışlardan yüksek kaliteli alt küme seçiminde kolaylık sağlar ve akışa yenilikçi bir katkıdır. Bu yaklaşım, zayıf denetimli öğrenme içeren sistemlere, literatürde bulunan güvenli sınıflandırma ve DivideMix (Northcutt et al., 2021; Li et al., 2020) gibi sağlam eğitim yöntemlerinin pratik mühendislik uyarlaması olarak hizmet eder. Bu, sistemin düşük güvenli eğitim örneklerinin dahil edilmesinin yol açabileceği potansiyel performans düşüşünü en aza indirmesine yardımcı olur.
İçerik analizi ve yaş tahmini, eşzamanlı olarak ilerledi ve bu kombinasyonu çalışmaya entegre etti. Bu entegrasyon, literatürde yalnızca birkaç çalışmada tartışılmakta olup, riskli içerikte 18 yaş altındaki bireylerin görünürlüğünün belirlenmesine yönelik yeni bir sosyal koruma odak noktası sunmaktadır. Bu çerçeve, çoklu görev öğrenme paradigmaları bağlamında içerik sınıflandırması ve yaş tahminini birleştirilmiş bir optimizasyon sürecinde entegre etmektedir. Bu, kaynak paylaşımını ve genel model verimliliğini artırmaktadır. 
Kişi izleme modülü, kimlik sürekliliği sistemi oluşturan DeepSORT algoritmasının PersonTrackerManager bileşeniyle güçlendirilmiştir. Bu, bir video akışındaki aynı kişiye ait karelerin sistematik olarak bağlanmasını sağlamakta ve yanlış pozitif olasılığını azaltmak için risk puanlarının konsolide edilmesini sağlamaktadır. Bu yaklaşım, kimlik sürekliliği ile videonun işleme maliyetini dengeleyen bir teknikleri literatüre katkıda sağlamaktadır. ROC eğrisi analiziyle optimize edilen CLIP modelinin güven eşik değeri (PSEUDO_LABEL_RECORD_CLIP_THRESHOLD=0.75) kesinlik ve hatırlama dengesini sağlamış ve kalite odaklı etiketlemenin miktar odaklı etiketlemeden üstün olduğunu kanıtlamıştır. Bu bulgu, koruyucu ölçümlerin standart ayarlarında hassas etik alanlardaki (örn. çocuk koruma ve içerik filtreleme) doğruluk ve güven dengesine önemli bir referans oluşturmaktadır.
Uygulamaya yönelik katkılar, kurumsal gereksinimlerle birleştirilen sistemin akademik bulguları üzerine inşa edilmiştir. On-premises dağıtım yapısı ve sürümleme/rollback mekanizmaları, kurum içi veri gizliliği, kesinti süresi minimizasyonu ve operasyonel risklerin kurumsal ölçekte yönetimini sağlamaktadır. Bu nedenle, sistem bulut tabanlı çözümlerden bağımsız olarak, regülasyon uyumlu ve kurum içi (self-hosted/on premises) bir yapıya sahiptir. Otomatik etiketleme modülü ve kullanıcı geri bildirim döngüsü, özellikle yapay zekâ okur yazarlığı düşük kullanıcı gruplarının bulunduğu ortamlarda, manuel iş yükünü azaltmakta ve etiketleme tutarlılığını artırmaktadır. Ayrıca, Windows geliştirme ortamı/kapsayıcı ve güvenlik odaklı orta katman ile modern yazılım mühendisliği ilkeleri ile entegre edilmiş bir mimari sunmaktadır. Overlay mekanizması, Türkçe karakter desteği ve erişilebilirlik odaklı arayüz düzenlemeleri kullanıcı deneyimini iyileştirirken; 18 yaş altı bireylere yönelik özel uyarı sistemleri sosyal koruma gereksinimlerini karşılamak üzere  geliştirilmiştir. Çoklu dosya yükleme desteği ile tek dosya-tek iş prensibi ve riskli kare çevresi kırpma (frame cropping) yaklaşımı büyük ölçekli taşınabilir medya akışlarının verimli biçimde işlenmesini sağlamaktadır. Tüm bu nedenlerle, çalışma güven skorlama, zayıf gözetimli veri seçimi, kimlik sürekliliği, sürdürülebilir model güncelleme ve güvenli veri işleme alanlarında tek bir akademik ve pratik uygulama olarak bütünleşik bir çözümdür.
Bu bağlamda, sistem, içeriğin güvenliği alanında akademik ilkeleri kurumsal uygulamalarla birleştirerek, literatürde önerilen yöntemleri üretim ortamına uygulamakta ve yeniden kullanılabilir bir referans modeli sağlamaktadır.
PROJE GELİŞTİRME SÜRECİ ve ZAMAN ÇİZELGESİ
Projenin başlatılmasında ihtiyaç analizi evresi kritik ve uzun süreli bir faz olarak gerçekleşmiştir. Kurum içi paydaşlarla yapılan görüşmelerin gereksinim toplama süreçlerine olumlu olarak yanıt verilmesi, kişisel verilerin internet veya bulut ortamına çıkmaması gereksinimlerinin sıralıda en üst sıralarda yer alması, sistemin tamamen on-premises olarak kurgulanması gerekliliğini ortaya koymuştur. Bununla birlikte, içerik akışlarının çoğunlukla yüksek kapasiteli taşınabilir medyalardan (harici diskler, USB) topluca sağlanması, çoklu dosya yükleme arayüze erişim tasarlanırken. Ayrıca, büyük boyutlu medya dosyalarının analizi esnasında kaynakların uzun süre bekletilmesi, iş akışı verimliliği açısından tek dosya–tek iş kuralı sistemi getirmek zorunluluğuna, kuyruk kontrolü ve iptal sistemlerinin sistem mimarisine kazandırılmasına sebep olmuştur. Personelin yapay zekâ okuryazarlığı seviyesinin düşük olması, otomatik etiketleme sisteminin gerekliliğini artırırken, kullanıcı geri bildirim arayüzünün sade ve anlaşılır olması tasarım prensibi olarak kabul edilmiştir.
Tasarım aşamasında, REST ve WebSocket arayüzleri için şemalar ayrıntılı bir şekilde hazırlandı; güvenlik önlemleri (MIME doğrulama, dosya yolu güvenliği, oran sınırlama) ve performans kriterleri (kuvvet tabanlı işleme, model önbellekleme) mimaride alınan kararlarda merkezi bir rol oynadı. Geliştirme aşamasında, Flask/SQLAlchemy/Socket.IO tabanlı arka uç sistemleri OpenCLIP, YOLO ve InsightFace bileşenleri ile entegre edildi. Test aşaması kapsamlıydı ve birim testi, entegrasyon testi ve kullanıcı kabul testi dahil olmak üzere sistemin teknik doğruluğu ve kullanıcı deneyiminin değerlendirildiği süreçlerden oluşuyordu. Bakım ve sürdürülebilirlik aşaması, versiyonlama ve geri alma mekanizmaları, periyodik temizlik görevleri ve günlük izleme yoluyla gerçekleştirildi; bu, sistemin uzun vadeli stabilitesini ve güvenilirliğini üretim ortamlarında sağlamayı ve operasyonel ortamlardaki güvenilirliğinin korunmasını amaçlıyordu.
Projenin geliştirilmesi yaklaşık 12 aylık bir süreçte gerçekleştirilmiştir. İlk üç ay, ihtiyaç analizi ve tasarım evresine ayrılmış; paydaş toplantıları, güvenlik gereksinimlerinin belirlenmesi ve mimari kararlar bu süreçte tamamlanmıştır. Dört-sekiz aylık dönem geliştirme evresini kapsamış; Flask arka uç, SQLAlchemy ORM, Socket.IO entegrasyonu, OpenCLIP/YOLO/InsightFace model entegrasyonları, güvenlik ara bileşeni, kuyruk servisi ve kullanıcı arayüzü bu aşamada tamamlanmıştır. Dokuz-on birinci aylar test ve iyileştirme evresine ayrılmış; birim, entegrasyon ve kullanıcı kabul testleri yürütülmüş, performans darboğazları tespit edilip optimize edilmiş, sürümleme/rollback mekanizmaları eklenmiştir. On ikinci ay, dokümantasyon, bakım prosedürlerinin yazılması ve üretim dağıtım hazırlıklarını kapsamıştır. Bu zaman çizelgesi, kurumsal gereksinimler ve kaynak kısıtları göz önüne alınarak planlanmış; çevik (agile) ilkelerle küçük artımlarla ilerleme ve sürekli geri bildirim döngüsü benimsenmiştir. Her sprint sonunda paydaşlara demo sunulmuş, geri bildirimler bir sonraki sprint planına dahil edilmiştir. Bu yaklaşım, gereksinim değişikliklerine hızlı uyumu ve son kullanıcı memnuniyetini artırmıştır.
Şekil 1.2. Proje Takvimi

BÖLÜM 2 GENEL BİLGİLER VE LİTERATÜR
2.1. BİLGİSAYARLI GÖRÜ ve İÇERİK ANALİZİ TEMELLERİ
Görsel içerik analizinin amacı, bir görüntü veya video karesinin anlamlı bileşenlerinin sayısal temsilini içermekte ve bu temsillerin sınıflandırılması, tespiti veya yorumlanması gibi sonraki görevleri kapsamaktadır. Bu sürecin merkezinde, bir giriş görüntüsünün özelliklerinin veya derin temsillerinin öğrenimi yer almaktadır. Özelliklerin çıkarılması, ham piksellerin yüksek boyutlu, ancak anlamlı, vektör alanlarına dönüştürülmesini sağlar, böylece makine öğrenimi modelleri kavramları soyutlayabilir ve ayırt edebilir. Denetimli öğrenme senaryolarında, bu temsiller doğrudan insan etiketleri ile hizalanırken, zayıf denetimli ve yarı denetimli ortamlarda veri kalitesi ile güvenilirlik ve güven düzeyi kritik öneme sahiptir. Bu ortamlarda, etiket gürültüsü nedeniyle, modelin genelleme yeteneği önemli ölçüde zayıflayabilir. Sonuç olarak, puan güvenilirlik değerlendirmesi, belirsizlik modelleme ve veri temizleme mekanizmalarının kullanılması sağlanmalıdır.
Özellik normalizasyonu, derin öğrenme modellerinin üretim ortamlarında uygulanabilirliğini artıran temel aşamalardan biridir. Batch normalization, layer normalization ve L2 normalizasyonu gibi yöntemler; eğitim sürecinde istikrarlı gradyan akışı sağlamaya, temsil vektörlerinin ölçek tutarlılığını korumaya ve modelin genel öğrenme dinamiklerini dengelemeye yardımcı olur. Ancak, yaş grupları veya risk kategorileri gibi dağılımı dengesiz veri kümelerinde, modelin yanlılık (bias) üretme olasılığı artar. Bu tür durumlarda, weighted sampling, focal loss ve yeniden örnekleme (re-sampling) teknikleri sınıf dengesizliğini azaltmak için kullanılır. Öte yandan, model kalibrasyonu, eğitimli modellerin olasılık tahminlerinin gerçek olasılıklarla uyumlu olmasını sağlayarak, hatalı güven düzeylerinin yayılmasını önler. Ayrıca, hataların bir kısmı sistematik (epistemik belirsizlik), bir kısmı ise rastlantısal (aleatorik belirsizlik) niteliktedir. Bu ayrım, veri kaynaklı ve model kaynaklı belirsizliklerin analiz edilmesine olanak tanır ve tahmin güvenilirliğinin değerlendirilmesinde önemli bir rol oynar. ******
Etik boyutta, adalet (fairness) ve gizlilik (privacy) ilkeleri görsel veri analizinin temel tasarım ilkeleri arasında yer almaktadır. Fairness kavramı, modelin farklı demografik gruplar arasında tarafsız karar verebilmesini ölçen metrikleri (demografik parite, eşit fırsat, equalized odds vb.) içerir. Özellikle yaş, cinsiyet ve etnik köken değişkenleri içeren veri kümelerinde modelin ayrımcı davranış göstermemesi, sosyal açıdan kritik bir gerekliliktir. Gizlilik tarafında, differential privacy, bireylerin verilerinin istatistiksel anonimlik düzeyini koruyarak model eğitimi yapılmasını mümkün kılar. Federated learning (dağıtık öğrenme) yaklaşımı ise verinin merkezi sunuculara aktarılmadan, cihazlar üzerinde yerel olarak eğitilmesiyle veri gizliliği ve regülasyon uyumluluğu (ör. KVKK, GDPR) sağlar.
Görsel temsillerin öğrenilmesinde Konvolüsyonel Sinir Ağları (CNN) uzun yıllar temel yaklaşım olarak kullanılmıştır. CNN mimarileri, görüntülerdeki yerel desenleri (kenar, doku, renk geçişi) düşük seviyeden yüksek seviyeye ilerleyen hiyerarşik yapılar hâlinde öğrenir. ResNet mimarisi (He ve diğerleri, 2016), “residual connection” yapısıyla derin ağlarda gradyan sönümleme sorununu aşmış ve yüzlerce katman içeren derin ağların eğitilmesini mümkün kılmıştır. ResNet-50, ResNet-101 ve ResNet-152 varyantları, parametre sayısı ve derinlik açısından farklı uygulamalara uyarlanabilir. CNN tabanlı yaklaşımlar, nesne tespiti, yüz tanıma ve sahne analizi gibi görevlerde yüksek başarı göstermektedir.
Son yıllarda Transformer tabanlı mimariler, dikkat mekanizması (self-attention) sayesinde görsel görevlerde CNN’lere rakip veya üstün performans sergilemiştir. Vision Transformer (ViT) modeli (Dosovitskiy ve diğerleri, 2021), görüntüleri küçük yamalara (patch) bölerek her bir yamayı birer token olarak işler ve BERT benzeri mimariyle global bağlamı öğrenir. DETR (DEtection TRansformer) (Carion ve diğerleri, 2020) bu yapıyı nesne tespitine uyarlayarak, anchor-free ve set prediction mekanizmaları ile bounding box ve sınıf tahminini birlikte gerçekleştirir. Transformer tabanlı yöntemler, özellikle çoklu nesne sahnelerinde bağlamsal ilişkileri daha doğru modelleyebilme avantajı sunar.
Veri artırma (data augmentation) stratejileri, sınırlı veri kümelerinde modelin genelleme yeteneğini artırmak için kullanılmaktadır. Basit geometrik dönüşümler (döndürme, yansıtma, ölçekleme) ile başlayan bu yaklaşım, son dönemde mixup, cutmix ve RandAugment gibi ileri düzey yöntemlerle zenginleştirilmiştir (Shorten ve Khoshgoftaar, 2019). Bu teknikler, yapay olarak çeşitlilik yaratırken aşırı öğrenmeyi (overfitting) azaltır.
Nesne tespiti (object detection) ve görsel segmentasyon (image segmentation) görevleri, içerik analizi açısından kritik rol oynamaktadır. Nesne tespitinde sahnedeki varlıklar, sınırlayıcı kutular (bounding box: x, y, w, h) ve sınıf etiketleriyle birlikte belirlenir. YOLO (Redmon ve Farhadi, 2018) tek-aşamalı bir grid tabanlı yaklaşım kullanırken, Faster R-CNN (Ren ve diğerleri, 2015) iki-aşamalı bir yapı (region proposal + classification) benimser; DETR ise transformer tabanlı mimarisiyle farklı bir paradigma sunar. Segmentasyon görevinde ise her piksel bir sınıfa atanır (semantik segmentasyon) veya her nesne örneği ayrı maskelenir (instance segmentasyon) (Long ve diğerleri, 2015).
Bu temel yaklaşımlar, görsel içerik analizi kapsamında risk kategorilerinin tespiti, yaş tahmini ve kimlik takibi gibi çoklu görevlerin bir arada yürütülmesini mümkün kılmaktadır. Özellikle yaş tahmini görevinde yüz ROI (Region of Interest) çıkarımı ile regresyon tabanlı modellerin bütünleştirilmesi, sahne içindeki bireylerin bağlamsal olarak değerlendirilmesine olanak sağlamaktadır. Böylece, derin temsil öğrenimi, etik/gizlilik bilinci ve çoklu görevli öğrenme ilkeleri bir araya gelerek hem akademik hem de kurumsal gereksinimlere uyumlu bir görsel analiz çerçevesi ortaya koymaktadır.
2.2. TRANSFER/ARTIMSAL ÖĞRENME YAKLAŞIMLARI
Görsel içeriklerin analizi yalnızca piksel düzeyinde örüntü tanımayı değil, aynı zamanda bu örüntülerin dilsel ve anlamsal bağlamla ilişkilendirilmesini de gerektirir. Bu doğrultuda geliştirilen CLIP (Contrastive Language–Image Pre-training) modeli, metin ve görüntü temsillerini ortak bir uzayda eşleştirerek görsel anlayışın dilsel yönünü modellemektedir. CLIP, 400 milyon metin–görüntü çifti üzerinde kontrastif öğrenme yöntemiyle eğitilmiştir ve bir görüntü ile onu tanımlayan metin arasındaki benzerliği en üst düzeye çıkarmayı amaçlar (Radford ve diğerleri, 2021). Böylece model, önceden tanımlı sınıf etiketlerine gerek duymadan yalnızca metin istemleri (prompts) aracılığıyla sıfır-örnek (zero-shot) sınıflandırma yapabilmektedir. Bu özellik, içerik sınıflarının sıklıkla değiştiği ortamlarda modelin yeniden eğitilmeden yeni kavramlara genelleme yapabilmesini sağlar. CLIP’in açık kaynak sürümü olan OpenCLIP, LAION-5B gibi geniş ölçekli veri kümeleri üzerinde eğitilmiş varyantlarıyla akademik araştırmalardan kurumsal uygulamalara kadar farklı bağlamlarda kullanılabilir hâle gelmiştir (Schuhmann ve diğerleri, 2022).
CLIP’in temelinde yer alan Vision Transformer (ViT) mimarisi, görüntüleri küçük yamalara (patch) ayırarak her bir yamayı birer girdi token’ı olarak işler ve dikkat mekanizması (self-attention) aracılığıyla global bağlam ilişkilerini öğrenir. Bu yapı, konvolüsyonel ağların yerel desenlere odaklanan doğasından farklı olarak, sahne içindeki nesneler arasındaki bağlamsal ilişkileri yakalayabilme yeteneği kazandırır (Dosovitskiy ve diğerleri, 2021). Böylelikle CLIP, yalnızca sınıflandırma görevlerinde değil, aynı zamanda anlamsal doğrulama, risk kategorisi tanıma ve bağlam farkındalığı gerektiren içerik analizlerinde de yüksek doğruluk düzeyi sunar.
Nesne ve kişi tespiti alanında YOLO (You Only Look Once) mimarisi, hız ve doğruluk dengesi açısından öne çıkan tek-aşamalı bir yaklaşımdır. YOLO, girdi görüntüsünü grid tabanlı bir yapıya bölerek aynı anda hem nesne sınıflarını hem de konumlarını (bounding box koordinatlarını) tahmin eder (Redmon ve Farhadi, 2018). Modelin son sürümleri olan YOLOv7 ve YOLOv8, anchor-free yapı, CSP blokları ve “bag-of-freebies” teknikleriyle parametre verimliliğini artırmış, küçük nesnelerin tespitinde ve düşük ışık koşullarında doğruluk iyileştirmeleri sağlamıştır (Wang ve diğerleri, 2023). YOLO’nun bu uzamsal doğrulama kapasitesi, CLIP’in anlamsal sınıflandırma kabiliyetiyle birleştirildiğinde, sistem hem ne tür bir içeriğin hem de içerikteki nesnelerin nerede bulunduğunun eşzamanlı olarak belirlenmesini mümkün kılar. Böyle bir birleşim, özellikle şiddet, silah, taciz veya yetişkin temalı içerik gibi yüksek risk kategorilerinde yanlış pozitif oranlarını azaltarak kurumsal doğrulama süreçlerinde güvenilirliği artırır.
InsightFace mimarisi, yüz tanıma, yaş ve cinsiyet tahmini gibi yüz odaklı görevlerde endüstri standardı hâline gelmiş bir çözümdür. Sistem, RetinaFace bileşeni aracılığıyla yüz bölgesini (Region of Interest) tespit eder ve ArcFace kayıp fonksiyonunu kullanarak 512-boyutlu bir yüz temsili (embedding) üretir (Deng ve diğerleri, 2019a; Deng ve diğerleri, 2019b). ArcFace, açısal marjinal yumuşatma (angular margin softmax) yöntemiyle benzer yüzlerin temsil uzayında daha sıkı kümelenmesini, farklı bireylerin ise belirgin biçimde ayrılmasını sağlar. InsightFace ayrıca yaş ve cinsiyet başlıkları (Custom Age Head, Gender Head) aracılığıyla demografik tahmin yapabilmekte, bu da özellikle 18 yaş altı bireylerin riskli içeriklerde tespiti gibi sosyal koruma odaklı uygulamalarda önemli bir avantaj sunmaktadır. Böylece CLIP’in anlamsal bağlam çözümlemesi, YOLO’nun konumsal tespiti ve InsightFace’in kişi düzeyindeki analizi birlikte kullanılarak, çok-modelli (multi-modal) ve bağlamsal olarak tutarlı bir değerlendirme mekanizması oluşturulmaktadır.
Model geliştirme sürecinde transfer öğrenme ve artımsal öğrenme (incremental/continual learning) yaklaşımları, sistemin hem verimliliğini hem de sürdürülebilirliğini belirleyen temel bileşenlerdir. Transfer öğrenme, önceden geniş veri kümeleri üzerinde eğitilmiş modellerin bilgi birikimini yeni görev alanlarına aktarmayı amaçlar. Bu sayede, sınırlı etiketli veriyle çalışan sistemler dahi yüksek performans elde edebilir. Özellikle ImageNet üzerinde eğitilmiş ResNet veya ViT modelleri, görsel özniteliklerin genelleştirilebilir temsillerini sağlayarak eğitim süresini önemli ölçüde kısaltır (Pan ve Yang, 2010; He ve diğerleri, 2016). Fine-tuning sürecinde, yalnızca son katmanların yeniden eğitilmesi veya tüm ağın optimize edilmesi kararı, kaynak ve hedef alanlar arasındaki farkın büyüklüğüne (domain gap) bağlı olarak belirlenir (Howard ve Ruder, 2018).
Artımsal öğrenme ise modelin zaman içerisinde yeni verilerle güncellenirken önceki bilgilerini unutmadan öğrenmesini sağlar. Dinamik veri akışlarının bulunduğu sistemlerde, bu yaklaşım modelin sürekli yeniden eğitilme ihtiyacını ortadan kaldırarak öğrenmenin sürekliliğini destekler. Bu süreçte karşılaşılan en temel zorluk, modelin yeni bilgileri öğrenirken geçmiş bilgileri unutması, yani katastrofik unutma (catastrophic forgetting) problemidir. Bu sorun, literatürde üç temel stratejik yönelim çerçevesinde ele alınmaktadır. Düzenleme-tabanlı yaklaşımlar (örneğin Elastic Weight Consolidation), modelin belirli parametrelerinin önceki görevlerdeki önemine göre değişimini sınırlandırarak unutmayı azaltır (Kirkpatrick ve diğerleri, 2017). Tekrar-tabanlı yaklaşımlar, önceki görevlerden seçilmiş örnekleri veya temsilleri bellekte tutarak modelin bu verilerle birlikte yeniden eğitilmesini sağlar ve böylece bilgi bütünlüğünü korur (Rebuffi ve diğerleri, 2017). Mimari-tabanlı yöntemlerde ise model, her yeni görev için yeni alt-ağlar veya parametre blokları ekleyerek bilgiyi modüler biçimde genişletir (Li ve Hoiem, 2016). Bu üç yönelim birlikte kullanıldığında, sistem hem istikrar hem genişletilebilirlik hem de geçmiş bilgiye bağlılık bakımından dengeli bir öğrenme çerçevesi kazanır.
Kurumsal ortamda bu süreç sürümleme (versioning) ve geri dönüş (rollback) mekanizmalarıyla bütünleştirilmektedir. Her eğitim döngüsü, hiperparametre ayarları, veri versiyonu ve performans metrikleriyle birlikte metadata olarak kaydedilmekte; performans düşüşü veya veri tutarsızlığı tespit edildiğinde sistem otomatik olarak önceki sürüme dönmektedir. Böylece yalnızca modelin doğruluğu değil, aynı zamanda operasyonel sürdürülebilirliği ve güvenilirliği de sağlanmaktadır.
Sonuç olarak, CLIP, YOLO, InsightFace ve transfer/artımsal öğrenme yaklaşımlarının bütünleşik biçimde kullanımı, metinsel, görsel ve demografik bağlamı eşzamanlı olarak işleyen, kendini sürekli güncelleyebilen ve kurumsal güvenlik gereksinimlerine uyumlu bir yapay zekâ altyapısı oluşturur. Bu yapı, akademik açıdan çok-modelli temsillerin öğrenilmesine, uygulama düzeyinde ise sosyal koruma ve içerik güvenliği alanlarında yeni nesil çözümlerin geliştirilmesine katkı sağlamaktadır.
2.3. VERİ KALİTESİ ve GÜVEN SKORLAMA
Gerçek dünya verilerinde gürültü, etiketleme hataları ve dağılım kaymaları kaçınılmaz biçimde ortaya çıkmakta; bu durum, makine öğrenmesi modellerinin genelleme yeteneğini düşürmekte ve sistematik önyargıların oluşumuna zemin hazırlamaktadır. Veri gürültüsünün temel kaynakları arasında sensör bozulmaları, insan etiketçiler arasındaki yorum farklılıkları, dikkat dağınıklığı sonucu oluşan etiketleme hataları, otomatik veri toplama süreçlerinden (örneğin web scraping veya OCR hataları) kaynaklanan etiket sapmaları ve zamanla değişen veri dağılımları (domain shift) yer almaktadır. Bu tür bozulmalar, modelin güvenilirliğini azaltmakla kalmaz; aynı zamanda üretim ortamına taşındığında yanlış kararların alınmasına da neden olabilir.
Bu çalışmada, veri kalitesinin artırılması amacıyla çok-modelli uzlaşı sinyali ve CLIP tabanlı anlamsal doğrulama birlikte kullanılmaktadır. Farklı modellerin (örneğin CLIP, YOLO, InsightFace) aynı örnek için benzer tahminler üretmesi, örneğin yüksek güvenilirlik taşıdığını göstermektedir. Buna karşılık, modeller arasında önemli tahmin farkları oluştuğunda, bu durum verinin belirsiz veya hatalı olduğunu işaret etmektedir. Böylece model uyuşmazlığı (model disagreement) bir güvenlik göstergesi olarak işlev görmekte, zayıf veya yanlış etiketlenmiş örneklerin eğitimden elenmesine olanak tanımaktadır. CLIP tabanlı sistemlerde, pozitif ve negatif istemlerle elde edilen benzerlik skorları arasındaki fark (Δ = pos_max − neg_max) normalize edilerek 0–1 aralύπύnda bir gόven skoru oluώturulmaktadύr. CLIP benzerlik skorlarύ doπrudan 0–100 aralύπύnda όretildiπinden, farkύn sigmoid dφnόώόmόyle olasύlύk biηimine getirilmesi gόvenin sayύsallaώtύrύlmasύnύ saπlamaktadύr.
Modern derin aπlarύn bir diπer φnemli sorunu olasύlύk kalibrasyonudur. Literatόrdeki birηok ηalύώma, aπlarύn sύklύkla “aώύrύ gόvenli” (overconfident) tahminler όrettiπini, φrneπin tahmin olasύlύπύ %90 olan bir φrneπin gerηekte yalnύzca %70 oranύnda doπru ηύktύπύnύ gφstermiώtir (Guo ve diπerleri, 2017). Bu nedenle, modelin ηύktύ olasύlύklarύnύn doπru ώekilde kalibre edilmesi, sistem gόvenilirliπi aηύsύndan kritik φneme sahiptir. En yaygύn yφntemlerden sύcaklύk φlηeklendirmesi (temperature scaling), softmax fonksiyonuna sύcaklύk parametresi (T) ekleyerek olasύlύk daπύlύmύnύ yumuώatύr; T>1 deπerleri daha dόώόk gόvenli, T<1 deπerleri ise daha keskin olasύlύklar όretir. Alternatif bir yφntem olan Platt φlηeklendirmesi, doπrulama kόmesi όzerinde lojistik regresyon eπitilerek kalibrasyon parametrelerini φπrenir (Lin ve diπerleri, 2007).
Eώik deπeri seηimi, kalibrasyon sόrecinin ayrύlmaz bir parηasύdύr. Bu ηalύώma kapsamύnda eώik optimizasyonu, ROC (Receiver Operating Characteristic) ve PR (Precision–Recall) eπrileri όzerinden gerηekleώtirilmiώtir. ROC eπrisi, gerηek pozitif oranύ (TPR = TP/(TP+FN)) ile yanlύώ pozitif oranύ (FPR = FP/(FP+TN)) arasύndaki iliώkiyi gφsterirken; PR eπrisi, hassasiyet (precision = TP/(TP+FP)) ve geri ηaπύrma (recall = TP/(TP+FN)) dengesini sunar (Davis ve Goadrich, 2006). Φzellikle dengesiz veri kόmelerinde (φrneπin pozitif φrneklerin %5’ten az olduπu senaryolar), ROC eπrisi yanύltύcύ sonuηlar verebilir; bu nedenle PR eπrisi daha bilgilendirici bir φlηόt olarak tercih edilmiώtir. Ηok dόώόk eώik deπerleri (φrneπin 0.3), sisteme gόrόltόlό verilerin dahil olmasύna ve yanlύώ pozitif oranύnύn artmasύna yol aηarken; aώύrύ yόksek eώikler (φrneπin 0.95) pozitif φrneklerin elenmesine, dolayύsύyla veri ηeώitliliπinin azalmasύna neden olmaktadύr. Bu denge noktasύnύ belirlemek amacύyla eπri altύ alan (AUC) analizi yapύlmύώ ve optimum gόven eώiπi τ=0.75 olarak deneysel biηimde belirlenmiώtir.
Sistemdeki orta gόven aralύπύ (0.5–0.75) φrnekleri, otomatik etiketleme yerine insan-dφngόde (human-in-the-loop) bir gφzden geηirme kuyruπuna yφnlendirilmektedir. Bu strateji, tam otomatikleώtirilmiώ sistemlerin neden olabileceπi φnyargύ birikimini ve hatalύ etiketlerin eπitim verisine girmesini engellerken, insan uzmanlύπύnύn yalnύzca belirsiz durumlarda devreye girmesini saπlayarak operasyonel verimliliπi artύrmaktadύr.
Model gόveninin analitik olarak deπerlendirilebilmesi iηin belirsizlik tahmini (uncertainty estimation) de sisteme entegre edilmiώtir. Belirsizlik, genellikle iki temel bileώene ayrύlmaktadύr: epistemik belirsizlik, modelin bilgi eksikliπinden veya veri azlύπύndan kaynaklanmakta; aleatorik belirsizlik ise verinin doπasύnda bulunan rastlantύsal gόrόltό ve etiket hatalarύndan doπmaktadύr. Epistemik belirsizlik, modelin yeni veya nadir φrneklerle karώύlaώtύπύnda yaώadύπύ kararsύzlύπύ temsil ederken; aleatorik belirsizlik, girdi sinyalinin iηsel tutarsύzlύklarύnύ yansύtύr. Bayesian yaklaώύmlar, φzellikle Monte Carlo Dropout tekniπiyle (MC Dropout), birden fazla ileri geηiώ (forward pass) sonucunda tahmin varyansύnύ φlηerek belirsizlik miktarύnύ nicelleώtirir (Hendrycks ve Gimpel, 2017). Ansambl yφntemleri (ensemble methods) ise farklύ modellerin tahminlerini bir araya getirir; dόώόk varyans durumunda uzlaώύ yόksek, dolayύsύyla belirsizlik dόώόktόr.
Veri kalitesinin sayύsal olarak deπerlendirilmesi iηin ηeώitli φlηόtler kullanύlmaktadύr. Etiket tutarlύlύπύ, aynύ φrneπe farklύ etiketηilerin ne φlηόde benzer kararlar verdiπini φlηer; φzellik ηeώitliliπi, veri kόmesinin farklύ demografik veya baπlamsal gruplarύ kapsayύp kapsamadύπύnύ deπerlendirir. Ayrύca demografik denge (yaώ, cinsiyet, etnik kφken daπύlύmύ) ve teknik kalite φlηόtleri (φrneπin ηφzόnόrlόk >112Χ112, bulanύklύk φlηόtό Laplacian varyansύ >100, sinyal-gόrόltό oranύ >20 dB) veri kόmesinin gόvenilirlik dόzeyini belirleyen ek faktφrlerdir. Bu gφstergelerin her biri, eπitim sόrecinde model baώarύmύnύ farklύ yφnlerden etkilemekte; dolayύsύyla veri kalitesi deπerlendirmesi yalnύzca etiket doπruluπuna deπil, aynύ zamanda ηeώitlilik, denge ve teknik bόtόnlόπe de dayandύrύlmaktadύr.
Veri kόmelerinde etiket hatalarύ, daπύlύm kaymalarύ ve sistematik φnyargύlar, model φπrenme etkinliπini dόώόrmekte ve genelleme kapasitesini sύnύrlamaktadύr. Bu baπlamda, literatόrde φnerilen yφntemler; etiket gόrόltόsόnόn modellenmesi, robust eπitim ve seηici φrnek kullanύmύ eksenleri όzerinden geliώmiώtir. Confident Learning yaklaώύmύ, sύnύf koώullu gόrόltό matrisini istatistiksel olarak modelleyerek hatalύ φrnekleri tespit etmekte ve veri temizliπi saπlamaktadύr (Northcutt ve diπerleri, 2021). Gόrόltόlό etiketli veri ile eπitimde, erken φπrenme etkisi (temiz φrneklerin φncelikli φπrenilmesi) ve φrnek seηimi/aπύrlύklandύrma stratejileri performansύ artύrmaktadύr (Chen ve diπerleri, 2019).
Bu tezde, benzer ilke φrnek-bazlύ aπύrlύklύ MSE kaybύ ile uygulanmύώ; yόksek CLIP gόvenli φrnekler eπitime daha fazla katkύ saπlamaktadύr. Ayrύca, model tahmin uyuώmazlύπύ (Buffalo-L vs. Custom Age Head) dόώόk gόvenli φrnekleri iώaret etmekte ve ηapraz testler ile en gόvenilir φrnekler seηilmektedir (Yu ve diπerleri, 2019). CLIP kontrastif φn-eπitimi, doπal dil denetimi ile ortak metin-gφrόntό yerleώtirmesi φπrenerek anlamsal benzerliπi gόvenilir bir kalite gφstergesine dφnόώtόrmekte; istem-temelli deπerlendirme, yorumlanabilir ve kontrol edilebilir bir katman oluώturmaktadύr (Radford ve diπerleri, 2021; Khattak ve diπerleri, 2023).
Tez kapsamύnda, ηok-modelli uzlaώύ yaklaώύmύ (Buffalo-L ve Custom Head ηύktύlarύ) CLIP tabanlύ metin-temelli gόven skorlarύ ile birleώtirilmiώ ve zayύf gφzetimli akύώlardan nitelikli altkόmelerin seηimi saπlanmύώtύr. Bu yφntem, literatόrde φnerilen robust eπitim teknikleri ile gφrό-dil (vision-language) tabanlύ anlamsal deπerlendirmeyi bir araya getirerek hem doπruluk hem de veri gόvenliπi aηύsύndan gόηlό bir ηerηeve sunmaktadύr. Sonuη olarak, ηalύώma veri kalitesini artύrmak ve model gόvenini sistematik biηimde φlηmek amacύyla, ηok-modelli uzlaώύ, kalibrasyon temelli gόven skorlama, belirsizlik tahmini ve insan-dφngόde gφzden geηirme yaklaώύmlarύnύ bόtόnleώtiren bir yapύ ortaya koymaktadύr. Bu bόtόnleώik yaklaώύm, yalnύzca istatistiksel doπruluπu deπil, aynύ zamanda etik ve operasyonel gόvenilirliπi de gφzeten bόtόncόl bir veri yφnetim ηerηevesi olarak deπerlendirilmektedir.
2.4. UYGULAMA ODAKLI ÇALIŞMALAR ve BOŞLUK ANALİZİ
Mevcut literatür, büyük ölçüde Batı dillerine ve kültürel temsillerine odaklanmış veri kümeleri üzerine inşa edilmiştir. ImageNet, COCO, CelebA ve UTKFace gibi yaygın veri setleri, ağırlıklı olarak İngilizce etiketler ve Batı toplumlarına özgü demografik dağılımlar içermektedir. Bu durum, modellerin farklı kültürel bağlamlarda genelleme yapma kapasitesini sınırlamakta; özellikle Türkçe gibi düşük kaynaklı dillerde ve farklı toplumsal normlara sahip toplumlarda, içerik sınıflandırma performansının düşmesine yol açmaktadır. Türkçe bağlamda, toplumsal davranış kalıplarına özgü görsel göstergelerin örneğin yakın temas biçimleri, jest ve mimiklerin anlam farklılıkları, giyim ve mahremiyet normlarının sınıflandırma çıktıları üzerindeki etkisi, literatürde yeterince derinlemesine incelenmemiştir.
Benzer biçimde, içerik moderasyonu konusundaki çalışmalar da çoğunlukla İngilizce dilinde, Batı kültürü çerçevesinde yürütülmektedir. Nefret söylemi, şiddet veya yetişkin içerik tespiti gibi alanlarda kullanılan istem setleri (prompt templates) ve risk kategorileri, genellikle Batı kültürünün sosyal kodlarını yansıtmaktadır. Türkçe ve yerel kültürel bağlama özgü semantik varyantların, jestsel veya dilsel nüansların dikkate alınmaması, modellerin yanlış pozitif ve yanlış negatif oranlarını artırmakta; bu da içerik güvenliğini sağlama süreçlerinde ciddi doğruluk kayıplarına yol açmaktadır. Literatürde Türkçe içerik moderasyonu için özel olarak tasarlanmış istem setleri, bağlamsal filtreleme stratejileri veya yerelleştirilmiş etiketleme yönergeleri sınırlı düzeydedir. Özellikle Türkçe bağlamda jest ve mimik kullanımı, kişiler arası fiziksel mesafe, giyim-kuşam normları ve sosyal etkileşim biçimleri gibi kültürel göstergelerin görsel sınıflandırma performansına etkisi sistematik olarak ele alınmamıştır. Bu durum, büyük ölçüde mevcut veri kümelerinin Batı merkezli görsel temsillerle sınırlı olmasından kaynaklanmakta; bu da Türk kültürel bağlamında üretilen içeriklerin model tarafından yanlış veya eksik değerlendirilmesine yol açabilmektedir. Bu eksiklik, özellikle kamu kurumları veya sosyal koruma odaklı uygulamalarda, modellerin karar mekanizmalarının yerel normlarla uyumsuz sonuçlar üretmesine neden olabilmektedir.
Çok‑dilli ve çok‑kültürlü içeriklerde semantik belirsizlikler ve bağlam kaymaları daha belirgindir; istem tasarımında yerelleştirilmiş söz öbekleri ve kültürel imleçler tercih edilmelidir. Görsel sahnelerde aynı nesnenin farklı kültürel kabul düzeyleri (ör. kamusal alanda yakın temas) sınıflandırma kararını etkiler. Geliştirilen uygulama kullanıcı geri bildirimlerinden beslenerek modelin gelişmesi sağlanabilmektedir.
Öte yandan, akademik literatürde yöntemsel olarak güçlü birçok model önerilmesine karşın, üretim (production) aşamasına taşınabilir sistem mimarilerinin ayrıntılarına yeterince yer verilmemektedir. Sürümleme (versioning), geri alma (rollback), kuyruk yönetimi, iptal mekanizmaları, on-premises dağıtım, WebSocket tabanlı gerçek zamanlı bildirim sistemleri ve dosya yol politikaları gibi pratik mühendislik bileşenleri, genellikle deneysel aşamada göz ardı edilmekte; bu da araştırma bulgularının operasyonel sistemlere aktarılmasını güçleştirmektedir. Akademik prototiplerin çoğu, yüksek doğruluk oranları sunsa da, güvenlik, gizlilik, sürdürülebilirlik ve sistem kararlılığı açısından üretim ortamı gereksinimlerini karşılayamamaktadır.
Video analizinde kişi takibi (person tracking) genellikle kimlik sürekliliği (identity persistence) amacıyla kullanılmakta; DeepSORT ve benzeri algoritmalar, bounding box koordinatları ve embedding temsilleri aracılığıyla her bireye benzersiz bir kimlik atayarak nesne takibini sürdürmektedir (Wojke ve diğerleri, 2017). Ancak bu takip süreçlerinin içerik risk skorları ve yaş tahmini çıktılarıyla bütünleştirilmesine ilişkin sistematik bir çerçeve literatürde bulunmamaktadır. Bu eksiklik hem hesaplama verimliliği hem de semantik bütünlük açısından önemli bir sınırlılık oluşturmaktadır.
Bu tez kapsamında geliştirilen sistem, söz konusu boşluğu kapatmak amacıyla içerik analizi (OpenCLIP + YOLO), yaş tahmini (InsightFace) ve kişi takibi (DeepSORT + PersonTrackerManager) bileşenlerini tek bir video analiz hattında bütünleştirmiştir. Her birey için benzersiz bir kimlik (unique ID) üretilmiş, video boyunca kimlik sürekliliği korunmuş ve her kişi için en güvenilir kare seçilerek içerik risk skorları ile yaş bilgisi birlikte overlay katmanında sunulmuştur. Aynı bireyin farklı sahnelerde tekrar görünmesi durumunda önceki yaş tahmininin kimlik bazında yeniden kullanılması hem gereksiz hesaplama maliyetini azaltmış hem de tahmin kararlılığını artırmıştır. Uzun süreli video akışlarında kimlik kayıplarını önlemek için MAX_LOST_FRAMES ve TRACKING_RELIABILITY_THRESHOLD gibi parametrelerin dinamik biçimde ayarlanabilir olması, sistemin üretim ortamına uyarlanabilirliğini güçlendirmiştir.
Bu birleşik yaklaşım, içerik analizi ve yaş tahmininin bütünleşik olarak yürütülmesini sağlayarak sosyal koruma odaklı uygulamalar için yenilikçi bir çözüm ortaya koymaktadır. Böylece çalışma, literatürdeki ayrık yaklaşımların sınırlılıklarını aşarak hem teknik hem etik düzlemde yeni bir uygulama çerçevesi sunmaktadır.
Mevcut literatürde içerik analizi ve yaş tahmini genellikle birbirinden bağımsız araştırma alanları olarak ele alınmaktadır. İçerik moderasyonu çalışmaları ağırlıklı olarak şiddet, istismar veya uygunsuz materyal gibi risk kategorilerinin tespitine odaklanırken, yaş bilgisini değerlendirme sürecine dâhil etmemektedir. Buna karşılık, yaş tahmini literatürü yüz tabanlı regresyon ve sınıflandırma yöntemleriyle ilgilenmekte; ancak içerik bağlamını ya da sahne düzeyindeki risk skorlarını hesaba katmamaktadır. Bu ayrışma, özellikle sosyal koruma perspektifinden bakıldığında, 18 yaş altı bireylerin yüksek riskli içeriklerle ilişkilendirilmesinin tespitinde ciddi bir boşluk yaratmaktadır.
Bu çalışma söz konusu boşlukları bütüncül biçimde ele almakta, yerel bağlamı gözeten güven skorlama ve artımsal güncelleme düzeneklerini bir arka uç mimarisi ile birleştirmektedir. Bu bütünleşik yapı, akademik düzeyde geliştirilen yöntemleri, operasyonel olarak sürdürülebilir bir sistem mimarisine dönüştürmektedir. Sürümleme ve rollback mekanizmaları, kuyruk temelli iş yükü yönetimi ve güvenli dosya erişim politikaları gibi bileşenler, akademik yöntemlerin pratik karşılıklarını oluşturarak, sistemin ölçeklenebilirliğini ve güvenilirliğini artırmaktadır. Ayrıca Türkçe istem varyantlarının ve kültürel bağlam ayarlamalarının (örneğin mutfak-bıçak bağlamının kültürel yorum farkları) sistematik biçimde tanımlanması, yerelleştirme literatüründeki önemli bir boşluğu doldurmakta ve gelecekteki çalışmalar için yeni bir referans çerçevesi sunmaktadır.
2.5. İÇERİK MODERASYONU ve ÇOK MODELLİ YAKLAŞIMLAR
Son yıllarda, içerik moderasyonu alanındaki çalışmalar, yalnızca tekil kipli (unimodal) analizlerden çoklu-modelli (multi-modal) sistemlere doğru önemli bir dönüşüm göstermektedir. Eğitim odaklı araştırmalar yaygın olmakla birlikte, güncel literatür giderek artan biçimde görsel ve metinsel işaretlerin birlikte ele alındığı bütünleşik düzeneklere yönelmiştir. İçerik moderasyonu, zararlı veya uygunsuz içeriklerin tespiti ve filtrelenmesini amaçlayan çok boyutlu bir süreçtir; spam, nefret söylemi, şiddet, yetişkin içerik ve dezenformasyon gibi kategorilerde uygulanmaktadır. Otomatik moderasyon sistemleri, insan moderatörlerin maruz kalma riskini azaltırken verimliliği artırır; ancak yanlış pozitif (masum içeriğin engellenmesi) ve yanlış negatif (zararlı içeriğin gözden kaçması) dengesinin doğru biçimde kurulması, sistem güvenilirliği açısından kritik öneme sahiptir.
Bu bağlamda, CLIP tabanlı temsil yaklaşımları, istem (prompt) temelli sıfır-örnek (zero-shot) sınıflandırma yeteneği sayesinde, zararlı içerik, nefret söylemi veya uygunsuz sahnelerin değerlendirilmesinde esnek bir temel sunmaktadır (Radford ve diğ., 2021; Schuhmann ve diğ., 2022). CLIP, sınıf tanımlarını doğal dil ifadeleriyle temsil ettiği için yeni risk türlerine hızlı biçimde uyum sağlayabilir. Geleneksel yöntemlerde (örneğin SVM veya CNN tabanlı sınıflandırıcılar), yeni bir kategori eklemek için modelin yeniden eğitilmesi gerekirken, CLIP yalnızca yeni bir istem eklenmesiyle genişletilebilir. Bu yönüyle, model mimarisi sabit kalırken bilgi alanı dinamik biçimde genişletilebilir. Çoklu-modelli istem öğrenme (Multi-modal Prompt Learning, MaPLe) yaklaşımları ise, görsel ve metinsel istemleri eşzamanlı olarak uyarlayarak aktarım (transfer) verimliliğini artırmakta ve modelin yorumlanabilirliğini güçlendirmektedir (Khattak ve diğ., 2023). İstem mühendisliği (prompt engineering) sürecinde kullanılan tanımlamaların özgüllüğü, model performansını doğrudan etkilemektedir; örneğin genel bir istem (“violence”) belirsizlik yaratabilirken, daha spesifik bir ifade (“physical violence with weapons”) ayrıştırma gücünü artırmaktadır.
Çoklu-modalli nefret söylemi araştırmaları, metin ve görüntü arasındaki örtük ilişkilerin tespitinde tek kipli modellerin yetersiz kaldığını ortaya koymuştur. Örneğin Hateful Memes veri kümesi (Kiela ve diğ., 2020), yalnızca metne veya yalnızca görüntüye dayalı sınıflandırmaların, zımni anlam farklarını yakalayamadığını göstermiştir. Bir meme’de metin tarafsız görünebilirken, görsel saldırgan olabilmekte veya tam tersi bir durum söz konusu olabilmektedir. Bu nedenle, çoklu-modelli yaklaşımlar, her iki işaretin birlikte değerlendirilmesiyle daha güvenilir sonuçlar üretebilmektedir. Ayrıca, nesne ve sahne bağlamını hesaba katan gerçek zamanlı tespit yöntemlerinin entegrasyonu, temsil benzerliği yüksek ancak bağlamsal olarak zararsız olan içeriklerin yanlış pozitif olarak sınıflandırılmasını önleyebilmektedir. Örneğin gündelik mutfak sahnelerinde yer alan kesici aletlerin yanlış pozitif etkisi, sahne bağlamındaki mutfak nesneleri (örneğin ocak, buzdolabı, tezgâh) aracılığıyla dengelenmelidir (Redmon ve Farhadi, 2018; Wang ve diğ., 2023). Bu çalışmada geliştirilen bağlamsal ayarlama mekanizması, YOLO nesne tespiti çıktılarından elde edilen bilgiye dayalı olarak CLIP skorlarını dinamik biçimde yeniden ölçeklendirmektedir; böylece, belirli sahne bağlamlarında risk skorları uygun katsayılarla düşürülerek yanlış pozitif oranı azaltılmaktadır.
Diğer taraftan, kötü amaçlı örnek saldırıları (adversarial examples), görsel girdilerde insan gözüyle fark edilemeyecek küçük değişiklikler oluşturarak modelin tahminlerini yanıltabilmektedir (Goodfellow ve diğ., 2015). Üretim ortamında güvenilir bir moderasyon sistemi kurmak için bu tür saldırılara karşı dayanıklılığın (adversarial robustness) sağlanması zorunludur. Bu kapsamda, düşman örneklerle yeniden eğitim (adversarial training) ve defensive distillation gibi savunma stratejileri öne çıkmaktadır. Ayrıca, model açıklanabilirliği (explainability) yöntemleri, model karar süreçlerinin şeffaflığını artırarak kullanıcı güvenini güçlendirmektedir. Örneğin Grad-CAM (Selvaraju ve diğ., 2017) yöntemi, modelin hangi görüntü bölgelerine odaklandığını ısı haritası biçiminde görselleştirirken, attention map analizleri transformer tabanlı modellerde hangi yama (patch) bölgelerinin karar sürecine katkı sağladığını ortaya koymaktadır.
Bu çalışmada, OpenCLIP tabanlı temsil benzerliği, YOLO nesne ve sahne bağlamı ile kişi odaklı yaş tahmini sinyalleri bir araya getirilerek içerik analizi sürecinde çoklu-modelli bir yapı oluşturulmuştur. Geliştirilen bağlamsal ayarlama düzenekleri (örneğin “mutfak-bıçak” veya “parti-şişe” senaryoları), yanlış pozitif oranlarını azaltırken, kullanıcıya görsel açıklama desteği sağlayan YOLO tespit listesi aracılığıyla sistemin açıklanabilirliğini de güçlendirmektedir. Böylece çalışma, yalnızca sınıflandırma doğruluğunu artırmakla kalmamakta, aynı zamanda güvenilir ve kullanıcı-şeffaf bir içerik moderasyonu altyapısı sunmaktadır.
BÖLÜM 3 SİSTEM ve MİMARİ
3.1. GENEL MİMARİ
Uygulama, Python/Flask tabanlı arka uç, kalıcı veritabanı bileşeni (SQLAlchemy), eş-zamansız iş kuyruğu, gerçek zamanlı bildirim altyapısı (Flask-SocketIO) ve kalıcı dosya depolama bileşenlerinden oluşmaktadır. İstemci tarafı, HTTP/JSON ve WebSocket kanalları aracılığıyla arka uç ile iletişim kurmakta, üretim koşulları için yeniden başlatılabilirlik, idempotent başlangıç görevleri ve sürümleme mekanizmaları dikkate alınmıştır. Mimari, modüler yapısı sayesinde her bileşenin bağımsız geliştirilmesini, test edilmesini ve gerektiğinde yeniden yapılandırılmasını desteklemektedir. Bu kapsamda, routes kataloğu HTTP uç noktalarını, services iş mantığını, ai katalogu model entegrasyonlarını, utils ise yardımcı fonksiyonları barındırır; bu ayrım, separation of concerns ilkesine uygun olup bakım ve ölçeklenebilirliği kolaylaştırmaktadır.
Veritabanı katmanı (models/), ORM tabanlı soyutlama ile ilişkisel verileri yönetir; File, Analysis, ContentDetection, AgeEstimation, Feedback, ModelVersion ve CLIPTrainingSession gibi varlıklar birbirleriyle ilişkiler aracılığıyla bağlanmaktadır. Kuyruk servisi (queue_service.py), thread-safe Queue ve arka plan threadleri kullanarak eşzamanlı işleme imkânı sağlar; her iş, database_session context manager üzerinden izole SQLAlchemy oturumu ile yürütülmektedir. WebSocket servisi, Socket.IO ile oda bazlı yayın ve bağlantı yönetimi sağlamakta, emit_* fonksiyonları tüm servislerden erişilebilmekte ve merkezi socketio_instance.py üzerinden global erişim sunmaktadır. Dosya depolama altyapısı (storage/) uploads, processed ve models alt dizinleri ile düzenlenmiş, göreli yol politikası sayesinde platformlar arası uyumluluk sağlanmaktadır.
Bu genel mimari, yüksek eşzamanlılığa sahip kuyruk temelli arka plan işlemenin uç gecikmelerini azaltmadaki pratik etkilerinden yararlanmakta ve gerçek zamanlı bildirimleri oda bazlı sınırlayarak gereksiz yayın yükünü minimize etmektedir (Dean ve Barroso, 2013). Modüler yapı, yeni özelliklerin (ör. yeni risk kategorileri veya farklı model mimarileri) sisteme hızlı ve güvenli biçimde eklenmesine imkân vermekte, her modül bağımsız olarak test edilebilmekte ve gerektiğinde yeniden yapılandırılabilmektedir. Bu yaklaşım hem teknik ölçeklenebilirliği hem de operasyonel sürdürülebilirliği garanti etmektedir.
3.2. UYGULAMA YAŞAM DÖNGÜSÜ
Uygulamanın giriş noktası main.py dosyasıdır. Bu bileşen, süreç yönetimi ve sistem güvenilirliği açısından kritik olan başlatma görevlerini üstlenir: PID kaydı, sinyal yakalama (SIGTERM, SIGINT için graceful shutdown) ve çevresel günlükleme yapılandırmaları (seviyeler, formatlar, handler’lar) bu aşamada gerçekleştirilir. Ana uygulama bileşeni, app/__init__.py içindeki create_app(config_name) fonksiyonu aracılığıyla Flask örneğini ve Socket.IO sunucusunu birlikte başlatır. config_name parametresi, ‘development’, ‘testing’ ve ‘production’ gibi farklı çalışma ortamlarını temsil eder; bu esneklik, uygulamanın aynı kod tabanı üzerinde farklı dağıtım senaryolarına uyum sağlamasına olanak tanır.
Başlatma sürecini yöneten initialize_app(app) fonksiyonu yalnızca ana süreçte çalışacak şekilde tasarlanmıştır. Bu fonksiyon, veritabanı tablolarının oluşturulması ve bütünlük kontrolü (db.create_all()), gerekli depolama dizinlerinin (UPLOAD_FOLDER, PROCESSED_FOLDER, MODELS_FOLDER) var edilmesi, eski analiz çıktı ve geçici dosyaların temizliği (cleanup_old_analysis_results) ile model sürümlerinin dosya sistemi–veritabanı uyumunun sağlanması (ör. sync_age_model_versions_startup, sync_clip_model_versions_startup) görevlerini yürütür. Ayrıca kuyruk işleyicisi background thread üzerinde başlatılır; tüm bu adımlar idempotent biçimde tasarlanmıştır. Böylece uygulama yeniden başlatıldığında görevler güvenli biçimde yinelenebilir, mevcut durum korunur ve gereksiz yan etkiler oluşmaz.
Gerçek zamanlı iletişim altyapısı olan Socket.IO, app/socketio_instance.py dosyasında merkezi bir nesne üzerinden yönetilir. Bu tasarım, farklı modüllerin socket’e doğrudan erişmesini sağlarken circular import problemlerini önler. Socket.IO minimal parametrelerle yapılandırılmıştır (cors_allowed_origins="*", ping_timeout=720, ping_interval=60, async_mode='eventlet'). Eventlet monkey patching, engelleyici (blocking) I/O işlemlerini asenkron hâle getirerek uzun süren CLIP hesaplamaları sırasında dahi WebSocket bağlantısının yanıt verebilirliğini korur. Bu yapı, yüksek eşzamanlılık altında kuyruk-temelli arka plan işlemenin uç gecikmeleri düşürmesini ve gerçek zamanlı bildirimlerin oda bazlı iletimle optimize edilmesini sağlar. Sonuç olarak sistem, üretim koşullarında dayanıklı, performans açısından verimli ve yeniden başlatılabilir bir çalışma düzeni elde eder.
3.3. KONFİGÜRASYON SABİTLER, DURUM ve YOL HİYERARŞİSİ
Uygulamanın yaşam döngüsünde sürekliliği sağlayan temel bileşen, yapılandırma ve durum yönetimidir. Bu kapsamda geliştirilen config.py modülü, tüm çevresel değişkenleri, sistem yollarını ve çalışma zamanı parametrelerini merkezi olarak yönetir. .env dosyasını okuyarak geliştirme, test ve üretim ortamları arasında dinamik geçiş yapılmasına olanak tanır; log bastırma, uyarı yönetimi (örneğin TF_CPP_MIN_LOG_LEVEL, YOLO_VERBOSE) ve kaynak sınırlamaları bu katmanda tanımlanır. Aynı dosyada veritabanı bağlantısı, dosya depolama kök dizinleri (UPLOAD_FOLDER, PROCESSED_FOLDER, MODELS_FOLDER) ve içerik boyutu sınırı (500 MB) gibi temel parametreler yer alır. Bu yaklaşım, konfigürasyonun tekil bir kaynaktan yüklenmesi ilkesine dayanarak sistemin taşınabilirliğini, sürüm uyumunu ve bakım kolaylığını artırır.
Çalışma zamanı boyunca model ve analiz durumlarının tutarlı biçimde izlenebilmesi için iki hafif durum katmanı kullanılır. app/utils/model_state.py dosyası, aktif model sürümlerinin ve önbellek durumunun yönetimini gerçekleştirir; thread-safe kilitleme mekanizmasıyla eşzamanlı erişimlerden doğabilecek çakışmaların önüne geçilir. Buna paralel olarak app/utils/settings_state.py, analiz parametrelerinin ve son güncelleme zaman damgasının takibini sağlar. Parametre güncellemeleri REST API üzerinden iletildiğinde, hem app.config nesnesine hem de durum dosyasına yansıtılır; böylece geliştirme ortamında değişikliklerin otomatik yeniden yükleme yoluyla anında etkinleştirilmesi mümkün olur.
Model dizin yapısı, sistematik bir hiyerarşiyle düzenlenmiştir. Her model ailesi için temel, sürüm ve aktif yol bilgileri (BASE_PATH, VERSIONS_PATH, ACTIVE_PATH) belirlenmiş; yaş tahmini (age/buffalo_l, age/custom_age_head), içerik analizi (clip/ViT-H-14-378-quickgelu_dfn5b), nesne tespiti (detection/yolov8x) ve metin-görüntü sınıflandırması (content/openclip_classifier) gibi alt bileşenler bu yapıya entegre edilmiştir. Başlangıç senkronizasyonu aşamasında sistem, dosya sistemindeki model klasörlerini tarayarak veritabanındaki ModelVersion tablosu ile hizalar; eksik kayıtlar için yeni girişler oluşturulur, mevcut kayıtlar için ise veritabanında “aktif” olarak işaretli sürümler öncelikli kabul edilir. Böylece model dosyalarının fiziksel konumu ile veritabanı temsili arasında bütünlük korunur.
Bu yapı, yalnızca konfigürasyonun merkezi yönetimini değil, aynı zamanda sistemin operasyonel kararlılığını da güvence altına alır. Atomik güncelleme ilkesiyle çalışan model durumu mekanizması, geçici tutarsızlıkların önüne geçerken, kontrollü önbellek temizleme sayesinde bellek kullanım verimliliği sağlanır. Sonuç olarak sistem, hem yüksek düzeyde izlenebilir hem de yeni modellerin eklenmesi veya parametrelerin değiştirilmesi durumunda kesintisiz biçimde uyum sağlayabilir.
3.4. GÜNCELLENEBİLİR ANALİZ PARAMETRELERİ ve MODEL DURUMU
Uygulamanın analiz davranışı, büyük ölçüde belirli parametrelerin dengeli biçimde yönetilmesine dayanır. Bu parametreler, hem sistemin farklı veri koşullarına uyum sağlamasını hem de işlem doğruluğunun korunmasını sağlar. Tüm varsayılan değerler FACTORY_DEFAULTS sözlüğünde saklanır ve her bir parametrenin veri tipi ile geçerli aralıkları UPDATABLE_PARAMS içinde tanımlanmıştır. Bu yapı sayesinde sistem, fabrika ayarlarıyla güvenli biçimde başlar ve gerektiğinde dinamik olarak güncellenebilir hale gelir. REST tabanlı uç noktalardan gelen parametre değişiklikleri önce tür denetimine tabi tutulur; geçerliyse hem app.config içine hem de settings_state.py dosyasına atomik olarak yazılır. Her değişiklikte LAST_UPDATE zaman damgası güncellenir; geliştirme ortamında bu değişiklik Flask’in otomatik yeniden yükleme mekanizmasını tetikler ve yeni değerler anında uygulanır. Üretim ortamında ise güncellemelerin devreye alınması manuel yeniden başlatma ile gerçekleştirilir.
Parametreler, video ve görüntü analizinde modelin davranışını doğrudan etkileyen eşik değerleridir. FACE_DETECTION_CONFIDENCE, bir yüzün geçerli kabul edilmesi için gereken model güven düzeyini belirler. Varsayılan fabrika değeri 0.2’dir; bu, çoğu normal çözünürlüklü ve aydınlık sahnede güvenilir yüz tespiti sağlar. Daha düşük değerler, örneğin 0.1 civarı, algılamayı kolaylaştırır ve küçük veya kısmi yüzleri yakalayabilir ancak yanlış pozitifleri artırabilir; yüksek değerler, örneğin 0.5 veya üstü, yalnızca güçlü yüz tespitlerinin dikkate alınmasını sağlar, bu da düşük ışık veya kısmi yüzlerde kaçırma riskini doğurur.
TRACKING_RELIABILITY_THRESHOLD, kişi takibinde kimlik eşleşmesinin ne kadar güvenilir olduğuna karar verir. Fabrika değeri 0.5 olarak belirlenmiştir; bu değer, çoğu sahnede hem sürekliliği hem de yanlış kimlik oluşturma riskini dengeler. Eğer sahnede hızlı hareket veya geçici görünmezlikler varsa, değeri artırmak güvenliği artırır ancak kısa süreli kayıplarda izlemeyi kesebilir; düşürmek ise daha toleranslı takip sağlar fakat yanlış eşleşme riski artar.
ID_CHANGE_THRESHOLD, iki tespit arasındaki gömülü temsil mesafesinin hangi noktada artık farklı kişi olarak kabul edileceğini belirler. Varsayılan fabrika değeri 0.45’tir. Bu değer düşük tutulursa model farklı kişiler arasında daha hassas ayrım yapar ama aynı kişinin farklı açılardan görünen karelerinde yeni kimlik oluşturabilir; yüksek değer ise geçici açı ve pozisyon değişikliklerinde aynı kimliği korur ancak farklı kişileri karıştırma riski taşır.
MAX_LOST_FRAMES, bir kişinin kadrajdan geçici olarak kaybolduğunda sistemin kimliği kaç kare boyunca hafızada tutacağını belirler. Fabrika değeri 30 kare olarak belirlenmiştir. Bu parametre, kısa süreli kayıplarda kişi bağlantısının kopmadan sürdürülmesini sağlar. Daha düşük değerler (5-10 kare), hızlı kaybolan nesnelerde takip kopmasına yol açabilir; yüksek değerler (100-300 kare) ise uzun süre sahneden çıkmış kişiyi takip etmeye devam eder, yanlış bağlantı riskini artırır ama kesintisiz takip sağlar.
Son olarak, EMBEDDING_DISTANCE_THRESHOLD, iki yüz embedding’i arasındaki mesafenin aynı kişi kabul edilebilmesi için izin verilen üst sınırdır. Fabrika değeri 0.4 olarak belirlenmiştir; düşük değerler modelin farklı kişileri daha hassas ayırmasını sağlar, fakat düşük ışık veya düşük çözünürlükte aynı kişiyi farklı kabul etme riskini artırır. Yüksek değerler ise toleransı artırır, bu da geçici görsel bozulmalarda kimliği korumaya yardımcı olur.
Bu parametrelerin tümü, sistemin farklı veri kalitelerine ve senaryolara uyum sağlamasını mümkün kılar. Örneğin, düşük çözünürlüklü videoların analizinde FACE_DETECTION_CONFIDENCE düşürülerek daha fazla yüz algılanabilir; hızlı hareket veya kalabalık sahnelerde MAX_LOST_FRAMES ve TRACKING_RELIABILITY_THRESHOLD artırılarak kimlik sürekliliği korunabilir. Bu şekilde, analiz davranışı uygulamanın bağlamına göre dengelenebilir; sistem hem doğruluk hem de süreklilik açısından optimum noktada çalışır.
Model durumu yönetimi de aynı derecede hassas bir mekanizmadır. model_state.py dosyasında tutulan MODEL_STATE sözlüğü, her modelin aktif sürümünü ve son yükleme zamanını izler; _state_lock kullanılarak thread-safe biçimde güncellenir, böylece aynı anda birden fazla erişim olsa bile veri tutarlılığı korunur. Aktif model örnekleri _model_instances sözlüğünde önbelleğe alınır ve weak reference kullanımı, gereksiz model nesnelerinin bellekten otomatik olarak temizlenmesini sağlar, olası bellek sızıntılarını önler. Bellek temizleme işlemleri cleanup_models() fonksiyonları aracılığıyla yürütülür; CLIP, YOLO ve InsightFace modellerinin nesneleri bellekteki referanslardan arındırılır ve GPU belleği torch.cuda.empty_cache() ile boşaltılır. Versiyon geçişlerinde eski modeller önbellekte tutulmaz, reset_instance() fonksiyonu çağrılarak yeni sürüm yüklenir ve önbellek sıfırlanır. Her model aktivasyonu veya parametre değişikliğinde LAST_UPDATE zaman damgası yenilenir ve geliştirme modunda otomatik reload tetiklenir.
Sonuç olarak, güncellenebilir parametreler ile model durumu yönetimi bir bütünün iki parçası gibi çalışır: parametreler uygulamanın çevresel koşullara uyumunu sağlarken, model durumu mekanizması sistemin sürekliliğini ve kaynak güvenliğini garanti eder. Fabrika değerleri başlangıçta güvenli bir denge sunar; kullanıcı veya sistem tarafından yapılan ayarlamalar ise farklı çözünürlükler, hızlı hareket, düşük ışık veya kalabalık sahneler gibi değişken koşullarda performans ve doğruluğu optimize eder. Bu yapı, derin öğrenme tabanlı analiz süreçlerinde hem doğruluk hem de sürdürülebilirlik açısından dengeli, esnek ve açıklanabilir bir çerçeve sağlar.
3.5. VARLIK İLİŞKİ MODELİ ve DOSYA YÖNETİMİ
Uygulamanın veri yönetimi, hem analiz sonuçlarının hem de model sürümlerinin güvenli ve sistematik biçimde saklanmasını sağlayacak şekilde tasarlanmıştır. Veritabanı şeması, beş temel varlık ve ek yönetim tabloları çevresinde yapılandırılmıştır: File, Analysis, ContentDetection, AgeEstimation, Feedback, ModelVersion ve CLIPTrainingSession.
File tablosu, dosya yüklemelerinin meta verilerini içerir (filename, original_filename, file_path, file_size, mime_type, file_type, upload_date) ve her bir dosya bir veya daha fazla analiz kaydı ile ilişkilendirilebilir (1:N ilişki). Analysis, dosya üzerinde gerçekleştirilen analizlerin üst kaydını tutar; UUID ile tanımlanan id, dosya referansı (file_id), durum (status), analiz başlangıç ve bitiş zamanları, işlenen kare sayısı, saniyedeki kare oranı (frames_per_second), yaş analizini içerip içermediği (include_age_analysis), WebSocket oturumu ID’si (websocket_session_id), iptal durumu (is_cancelled) ve özet skorlar (overall_scores) gibi alanlar içerir. Her analiz birden fazla kare ve kişi tespitini barındırabilir, bu nedenle ContentDetection ve AgeEstimation tabloları ile 1:N ilişkiler kurulur.
ContentDetection tablosu, kare bazlı içerik skorlarını ve tespit edilen nesneleri JSON biçiminde saklar. Skorlar, şiddet, yetişkin içerik, taciz, silah, uyuşturucu ve güvenli içerik gibi kategorilere ayrılır. AgeEstimation, kişi bazlı yaş tahminlerini kare bilgisi, güven skoru, bounding box, işlenmiş görüntü yolu ve embedding string ile birlikte tutar. Feedback tablosu, manuel veya sözde etiketleri depolar; analiz ile ilişkilendirilebileceği gibi doğrudan yüz embedding’i üzerinden de kayıt yapılabilir. Bu yapı, hem eğitim hem de model güncelleme süreçlerinde veri kaynağının esnek kullanılmasını sağlar.
Model yönetimi için ModelVersion ve CLIPTrainingSession tabloları eklenmiştir. ModelVersion, model türü, sürüm numarası ve adı, aktiflik durumu, metrikler, kullanılan eğitim örnekleri, epoch sayısı, ağırlık dosya yolu ve kullanılan geri bildirim kimliklerini kaydeder. CLIPTrainingSession ise CLIP model eğitim oturumlarının isimlerini, metriklerini ve oluşturulma zamanlarını içerir.
İlişkiler ve kardinaliteler özetle şunlardır: bir File birden fazla Analysis içerebilir; her Analysis birden fazla ContentDetection ve AgeEstimation kaydı ile ilişkili olabilir; Feedback bağımsızdır ve isteğe bağlı olarak analiz veya doğrudan kişi bazlı kayıtlarla ilişkilendirilebilir. Cascade delete-orphan politikası, analiz silindiğinde ilişkili ContentDetection ve AgeEstimation kayıtlarının otomatik temizlenmesini sağlar. Böylece yetim kayıt birikimi engellenir. Foreign key kısıtlamaları, veri bütünlüğünü garanti eder; dosya silinmeden önce ilişkili analizlerin temizlenmesi zorunludur. İndeksler, sık sorgulanan alanlarda (ör. Analysis.status, AgeEstimation.person_id) performans optimizasyonu sağlar.
Dosya depolama hiyerarşisi, veritabanı ile entegre çalışacak şekilde tasarlanmıştır. Tüm içerik storage/ kökü altında organize edilir; yüklemeler uploads/, işlenmiş analizler processed/ ve modeller models/ dizinlerinde tutulur. Model dizinleri, taban model (base_model), sürümler (versions) ve aktif model (active_model) alt yapısı ile sürümlenebilir yapı kazandırır. Başlangıçta disk ve veritabanı kayıtları senkronize edilir; aktif model veritabanındaki kayıtlar ile hizalanır.
Güvenli dosya sunumu, göreli yol politikaları ile sağlanır. Tüm istemciye servis edilen dosyalar to_rel_path fonksiyonu aracılığıyla storage köküne göreli hale getirilir; Windows ve POSIX ayracı farklılıkları normalize edilir, böylece cross-platform uyumluluk sağlanır. Dosya uç noktaları (serve_processed_image, serve_analysis_frame, serve_uploaded_file) mutlak yol doğrulaması (to_abs_path + validate_path) ile güvenlik denetiminden geçer; path traversal veya kök dışı erişimler reddedilir. MIME türü otomatik belirlenir ve yalnızca izinli kökler üzerinden dosya sunumu yapılır. Bu çok katmanlı doğrulama hem güvenlik hem de depolama esnekliği sağlar; depolama kökü değişse bile veritabanında saklanan yollar geçerliliğini korur.
Bu bütünleşik yapı, veri bütünlüğü, sorgu performansı, güvenli dosya yönetimi ve model sürüm kontrolünü tek çatı altında toplar. Uygulama, analiz sonuçlarını güvenle depolarken, veri kaybını önler ve farklı çözünürlüklerdeki içerikler için sürdürülebilir bir çalışma ortamı sunar.
Şekil 3.5. Veri Tabanı ER Diyagramı


3.6. PLAFORM, UYGULAMA YAYINLAMA KATMANI
Uygulamanın mimarisi, geliştirme ve üretim ortamları arasında yüksek düzeyde platform bağımsızlık hedefiyle tasarlanmıştır. Geliştirme süreçleri Windows tabanlı sistemlerde yürütülürken, üretim ortamı Linux/Unix tabanlı sunucular üzerinde çalışmaktadır. Bu tercih, yapay zekâ uygulamalarının performans ve donanım erişimi açısından Linux ekosisteminde daha kararlı çalışmasıyla doğrudan ilişkilidir. GPU sürücüleri, CUDA ve cuDNN kütüphaneleri gibi düşük seviyeli hızlandırıcılar Linux’ta daha olgun bir desteğe sahiptir; ayrıca modern üretim ortamlarında yaygın olarak kullanılan Docker ve Kubernetes gibi konteyner teknolojilerinin doğal olarak bu platformlarda çalışması, sistemin gelecekte ölçeklenebilir ortamlara taşınmasını kolaylaştırmaktadır.
Uygulama çekirdeği Python dili ile geliştirilmiştir. Python’un geniş kütüphane ekosistemi, özellikle yapay zekâ tabanlı projelerde model eğitimi, veri işleme ve servis entegrasyonu alanlarında önemli avantajlar sağlar. PyTorch, dinamik hesaplama grafiği sayesinde derin öğrenme modellerinin esnek biçimde yürütülmesini mümkün kılar; yaş tahmini ve yüz tanıma süreçlerinde kullanılan InsightFace kütüphanesi bu altyapı üzerinde çalışmaktadır. TensorFlow/Keras kütüphaneleri, belirli modellerin dönüştürülmesi veya kıyaslanması için uyumlu biçimde entegre edilmiştir. OpenCV, video ve görüntü işleme aşamalarında temel araç olarak kullanılırken; NumPy ve SciPy, vektörleştirilmiş matematiksel işlemler ve istatistiksel analizler için destek sağlar. Web katmanı Flask çerçevesi üzerine kuruludur; bu yapı hem REST API uç noktalarını hem de Socket.IO aracılığıyla gerçek zamanlı bildirimleri barındırır. Veritabanı soyutlaması SQLAlchemy ORM ile sağlanmış, böylece farklı veritabanı sistemlerine geçişlerde kod düzeyinde minimal değişiklik yeterli hale getirilmiştir.
Platform bağımsızlığının sürdürülebilmesi için dosya ve yol işlemleri de özel olarak ele alınmıştır. os.path.normpath ve pathlib kullanımı sayesinde, Windows’taki ters eğik çizgi (\) ile Unix tabanlı sistemlerdeki eğik çizgi (/) farkı soyutlanmış, böylece dosya yolları her iki ortamda da uyumlu hale getirilmiştir. Çevresel değişkenler .env dosyasından yüklenmekte, DevelopmentConfig ve ProductionConfig sınıfları üzerinden ortam bazlı ayarlar (örneğin DEBUG, DATABASE_URL, USE_GPU) otomatik olarak uygulanmaktadır. Bu yapı, geliştirme, test ve üretim ortamları arasında geçişi sadeleştirirken, platform-spesifik kod bağımlılıklarını da en aza indirir.
Her ne kadar uygulama hâlihazırda tek bir güçlü GPU’ya sahip bir sunucuda çalışıyor olsa da, yazılım mimarisi container tabanlı ortamlara kolayca uyarlanabilir niteliktedir. Uygulama bağımlılıkları requirements.txt dosyasıyla tanımlanmıştır; bu sayede basit bir Dockerfile tanımı ile konteyner ortamı kısa sürede oluşturulabilir. Ortam değişkenlerinin ENV direktifleri ya da docker-compose.yml aracılığıyla dışarıdan yönetilmesi mümkündür. Statik dizinler (storage/, uploads/, processed/, models/) volume olarak bağlanabilir; böylece konteyner yeniden başlatıldığında veri bütünlüğü korunur.
Uygulama şu anda tek bir işlem örneği (instance) olarak çalışmakta ve otomatik ölçeklendirme (auto-scaling) kullanılmamaktadır. Bununla birlikte, mimari tasarım bu yeteneğe açık biçimde kurgulanmıştır. Gelecekte birden fazla GPU sunucusunun devreye alınması durumunda, Flask uygulaması yatay ölçeklenebilir hale getirilebilir; Socket.IO iletişimi için Redis tabanlı bir adapter eklenerek farklı örneklerin aynı analiz oturumlarına (örneğin analysis_<id>) eşzamanlı veri yayınlaması sağlanabilir. Veritabanı katmanı da benzer biçimde PostgreSQL veya MySQL gibi harici servislerle genişletilebilir; SQLAlchemy soyutlama katmanı bu geçişi kod düzeyinde neredeyse etkisiz kılar.
Ayrıca, sisteme entegre edilecek bir /health uç noktası, konteyner orkestrasyon araçları (Kubernetes Liveness/Readiness Probes) tarafından sağlık kontrolü amacıyla kullanılabilir. Böylece ilerleyen aşamalarda sistemin cloud-native veya on-premises altyapılarda izlenmesi ve ölçeklenmesi kolaylıkla sağlanabilir.
Sonuç olarak, sistem şu anda tekil donanım kaynakları üzerinde çalışmakta olsa da, tüm yapısal kararlar gelecekteki olası genişlemeleri öngören biçimde alınmıştır. Seçilen teknolojiler, hem mevcut kurulumun kararlı biçimde işlemesini hem de gelecekteki konteyner tabanlı dağıtımlar, yüksek erişilebilirlik senaryoları ve dağıtık GPU altyapıları için güçlü bir temel oluşturur.

3.7. KATMANLI MİMARİ ve VERİ AKIŞI
Sistem mimarisi, katmanlı yapı (layered architecture) ilkesine dayanmaktadır; bu tasarım, her katmanın belirli sorumlulukları üstlenmesi ve katmanlar arası arayüzlerin net tanımlanmasıyla bakım kolaylığı ve genişletilebilirlik sağlar. Mimari, dört temel katmandan oluşmaktadır: İstemci/UI Katmanı, Orta Katman, Arka Katman ve Veri/Model Katmanı.

İstemci/UI katmanı, web tarayıcısı üzerinde çalışan kullanıcı arayüzünü kapsar. Bootstrap framework'ü ile responsive tasarlanmış arayüz, dosya yükleme, analiz başlatma, sonuç görüntüleme ve geri bildirim gönderme işlevlerini sunar. Socket.IO client kütüphanesi, gerçek zamanlı bildirimler için WebSocket bağlantısını yönetir; AJAX (fetch API) ile REST uçlarına asenkron istekler gönderir.

Orta katman, HTTP isteklerini karşılayan REST API, gerçek zamanlı bildirimleri yöneten Flask-SocketIO ve iş yükü dengelemesini sağlayan kuyruk orkestrasyon bileşenlerini barındırır. Kuyruk servisi (app/services/queue_service.py), thread-safe Queue ile FIFO düzeninde işleri arka katmana iletir.

Arka katman, yapay zekâ modellerini ve eğitim servislerini içerir. ContentAnalyzer (app/ai/content_analyzer.py), OpenCLIP ve YOLO ile içerik risk skorları üretir; InsightFaceAgeEstimator (app/ai/insightface_age_estimator.py), Buffalo-L ve Custom Age Head ile yaş tahmini yapar.

Veri/Model katmanı, kalıcı veri deposu (SQLAlchemy ORM), dosya depolama (storage/) ve model sürüm deposunu kapsar. Veritabanı şeması File, Analysis, ContentDetection, AgeEstimation, Feedback, ModelVersion tablolarından oluşur.

Veri akışı: Kullanıcı dosya yükler → REST API doğrular → File kaydı → Analysis "pending" → kuyruk → AI servisleri → sonuçlar → WebSocket yayını → istemci alır.

3.8. SEQUENCE ve STATE DİYAGRAMLARI
Dosya yükleme ve analiz başlatma akışı: Kullanıcı POST /api/files → file_id → POST /api/analysis/start → Analysis kaydı → kuyruk → AI servisleri → sonuçlar → analysis_completed olayı.

Analiz yaşam döngüsü state diyagramı: PENDING → RUNNING → COMPLETED/FAILED/CANCELLED. Her durum geçişinde WebSocket olayı yayınlanır.

3.9. DAĞITIM MİMARİSİ ve ON-PREMISES KURULUM
Sistem on-premises topoloji ile tasarlanmıştır. Bileşenler: Nginx/Reverse Proxy, Flask + Socket.IO, Queue Workers, RDBMS, dosya sistemi.

Windows kurulumu: Python 3.10–3.11, venv, pip install -r requirements.txt, model indirme, .env oluşturma, python app.py.
Linux kurulumu: Ubuntu 22.04, venv, requirements.txt, systemd servis, sağlık kontrolü (health_check.sh).

BÖLÜM 4 YAPAY ZEKÂ MODÜLLERİ ve EĞİTİM

4.1. İÇERİK ANALİZİ (OpenCLIP)
ContentAnalyzer sınıfı, ViT-H-14-378-quickgelu mimarisi (632M parametre) ile içerik risk skorları üretir. Classification head: Linear(1024→512→256→5) + Sigmoid. Prompt engineering: Her kategori için 5 pozitif, 5 negatif istem. YOLO bağlamsal ayarlamaları: Mutfak-bıçak, silah tespit

i durumlarında skorları düzeltir. Kod: app/ai/content_analyzer.py.

4.2. YÜZ ve YAŞ TAHMİNİ (InsightFace + Özel Başlık)
Buffalo-L: det_10g.onnx (RetinaFace), rec.onnx (512-dim embedding), genderage.onnx. Custom Age Head: Linear(512→256→128→1), ~200K parametre. UTKFace ön-eğitimi: MAE≈2.7-2.9. CLIP paylaşımı (set_shared_clip): ~8-12 GB tasarruf. Çapraz sorgu: Buffalo-L vs Custom Head, yüksek net skor seçilir. Pseudo-label: CLIP güveni ≥0.75 → Feedback. Kod: app/ai/insightface_age_estimator.py.

4.3. EĞİTİM DÖNGÜSÜ ve AĞIRLIKLI KAYIP
Ağırlıklı MSE: L = (1/N) Σ w_i * (f(x_i) - y_i)², w_i = γ * C_final + (1-γ), γ≈0.8-1.0. Erken durdurma: val_loss iyileşmezse (patience=10) eğitim kesilir. IncrementalAgeModel: Base (UTKFace, frozen) + Fine-tune branch. Kod: app/services/incremental_age_training_service_v2.py.

BÖLÜM 5 GÜVEN SKORU ve VERİ KALİTESİ

5.1. ÇOK-MODELLİ UZLAŞI
C_agreement = exp(-|y₁ - y₂|/σ), σ=2.0. Kodda çapraz sorgu: Her model kendi + diğerinin tahminini CLIP ile doğrular, net skor yüksek olan seçilir.

5.2. CLIP TABANLI DOĞRULAMA
S(I,T) = 100 * cos(E_img, E_text). Prompt: Pozitif/negatif istemler. Δ = max(S_pos) - max(S_neg), C_clip = 1/(1+exp(-2Δ)), [0.1,0.9] sınırlı.

5.3. EŞİK ve KARAR KURALLARI
Bölüm 2.3'teki ROC/PR teorisi, τ=0.75 ile uygulanmıştır (bkz. Şekil 2.3). Üç aşamalı karar: ≥0.75 otomatik, 0.5-0.75 manuel, <0.5 red. Demografik denge, audit log. Kod: app/services/incremental_age_training_service_v2.py, app/ai/insightface_age_estimator.py.

BÖLÜM 6 ARKA UÇ UYGULAMASI

6.1. REST API
POST /api/files, POST /api/analysis/start, GET /api/analysis/<id>, POST /api/feedback. Kod: app/routes/*.py.

6.2. WEBSOCKET
RFC 6455, Socket.IO, oda bazlı yayın, ping/pong, disconnect iptal. Kod: app/socketio_instance.py, app/routes/websocket_routes.py.

6.3. GÜVENLİK
Oran sınırlama, güvenlik başlıkları (CSP, HSTS), MIME/magic-bytes, path traversal koruması. Kod: app/middleware/security_middleware.py, app/utils/*.py.

6.4. KUYRUK ve HATA
Thread-safe Queue, FIFO, analyze_file, update_progress, rollback. Asenkron yaş tahmini: ThreadPoolExecutor. Kod: app/services/queue_service.py, app/services/analysis_service.py.

6.5. VİDEO/GÖRSEL FARKLAR
Görsel: Tek kare analiz. Video: Kare örnekleme, DeepSORT, PersonTracker, overlay. Hesaplama tasarrufu: %99.9. Kod: app/services/analysis_service.py, app/utils/person_tracker.py.

6.6. 18 YAŞ ALTI
estimated_age < 18 + yüksek risk → kırmızı overlay, "UYARI: 18 Yaş Altı". Kod: app/services/analysis_service.py, app/utils/image_utils.py.

BÖLÜM 7 DENEYSEL KURULUM ve SONUÇLAR

7.1. ORTAM ve VERİ
Donanım: RTX 3060/3070/4090 (12-24 GB VRAM), 32-64 GB RAM. Yazılım: Python 3.9-3.11, PyTorch, OpenCLIP, YOLOv8, InsightFace, Flask. Üretim verisi: 450 analiz, 180K dosya, 303K yüz, 8K kontrol seti. Model eğitim: 3 yaş, 2 içerik. UTKFace: 23K yüz, 0-116 yaş. Tohumlar: 42, 52, 62.

7.2. ÖLÇÜTLER
MAE, MSE, ±3y/±5y accuracy (yaş). Precision, Recall, F1, Accuracy (içerik). İşlem süresi, bellek, throughput. Kişi-bazlı bölünme (data leakage önleme).

7.3. ABLATION (C1–C5)
C1 (Baseline): Buffalo-L, MAE 7.8±0.3. C2 (Tüm veri): MAE 7.0±0.4. C3 (Güven filtreli): MAE 6.1±0.2. C4 (Ağırlıklı): MAE 5.7±0.2. C5 (Tek bileşen): MAE 6.5±0.3.

7.4. BULGULAR
C4 en iyi. %60 veri azalması, performans artışı → veri kalitesi > veri miktarı. CLIP paylaşımı %50 bellek tasarrufu. Kişi takibi %99.9 hesaplama tasarrufu.

7.5. KARŞILAŞTIRMA
Bu Çalışma: MAE 5.7±0.2, İçerik 71%, On-prem. Google Vision: MAE 7.2±0.4, İçerik 68.5%. AWS: MAE 6.8±0.3. %60-70 maliyet tasarrufu.

BÖLÜM 8 SONUÇ ve GELECEK ÇALIŞMALAR

Sonuç: Çok-modelli güven skorlama, on-prem artımsal öğrenme, ROC eşik optimizasyonu, kişi takibi+içerik+yaş birleşimi, sürümleme/rollback, otomatik etiketleme, 18 yaş uyarı.

Gelecek: (i) Streaming (RTSP/HLS), (ii) Aktif öğrenme, (iii) Cross-domain, (iv) Türkçe istem, (v) Ölçeklenebilirlik, (vi) Adversarial/explainability, (vii) Hiperparametre optimizasyonu (Optuna, Bayesian), (viii) Canary deployment/A/B testing, (ix) Model distillation, (x) Federated learning, (xi) Çok dilli destek (Arapça, Farsça, İngilizce).

KAYNAKLAR

Radford et al., 2021 (CLIP). Dosovitskiy et al., 2021 (ViT). Schuhmann et al., 2022 (LAION). Redmon & Farhadi, 2018 (YOLO). Wang et al., 2023 (YOLOv7). Deng et al., 2019a/b (ArcFace, RetinaFace). Pan & Yang, 2010 (Transfer). Kirkpatrick et al., 2017 (EWC). Li & Hoiem, 2016 (LwF). Guo et al., 2017 (Calibration). Davis & Goadrich, 2006 (ROC/PR). He et al., 2016 (ResNet). Howard & Ruder, 2018 (ULMFiT). Hendrycks & Gimpel, 2017 (OOD). Rebuffi et al., 2017 (iCaRL). Loshchilov & Hutter, 2017 (SGDR). Smith, 2017 (CLR). Srivastava et al., 2014 (Dropout). Goodfellow et al., 2015 (Adversarial). Carion et al., 2020 (DETR). Kiela et al., 2020 (Hateful Memes). Dean & Barroso, 2013 (Tail at Scale). Wojke et al., 2017 (DeepSORT). Fette & Melnikov, 2011 (RFC 6455). Northcutt et al., 2021 (Confident Learning). Chen et al., 2019 (Noisy labels). Han et al., 2018 (Co-teaching). Li et al., 2020 (DivideMix). Yu et al., 2019 (Disagreement). Khattak et al., 2023 (MaPLe). Lin et al., 2007 (Platt). Shorten & Khoshgoftaar, 2019 (Augmentation). Ren et al., 2015 (Faster R-CNN). Long et al., 2015 (FCN). Selvaraju et al., 2017 (Grad-CAM). Karimi et al., 2020 (Medical noisy labels).
