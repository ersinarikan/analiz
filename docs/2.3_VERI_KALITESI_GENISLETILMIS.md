2.3. VERİ KALİTESİ ve GÜVEN SKORLAMA

Gerçek dünya verilerinde gürültü, etiketleme hataları ve dağılım kaymaları, veri seti hazırlanırken veya işleme sırasında konunun doğası gereği sıkça karşılaşılan bir durumdur. Eğitilen yapay zekâ modellerinin başarısı kullanılan veri setlerindeki verinin ve etiketinin doğruluğu ile doğru orantılıdır. Çok yüksek sayıda ve boyutta kullanılan verilerin etiketlerinin %100 doğru ve heterojen yapıda olması ulaşılabilir büyük veri setleri için çok olası olmamakla beraber makine öğrenmesi açısından değerlendirildiğinde bu hatalı eğitim verisi setleri modellerinin genelleme yeteneğini düşürmekte ve model başarısı açısından sistematik yorum farklarının oluşumuna zemin hazırlamaktadır. 

Veri gürültüsünün temel kaynakları arasında sensör bozulmaları, insan etiketçiler arasındaki yorum farklılıkları, dikkat dağınıklığı sonucu oluşan etiketleme hataları, otomatik veri toplama süreçlerinden (örneğin web scraping veya OCR hataları), dil yapılarından kaynaklanan etiket sapmaları ve zamanla değişen veri dağılımları (domain shift) yer almaktadır. Bu tür bozulmalar, modelin güvenilirliğini azaltmakta aynı zamanda gerçek çalışma ortamına taşındığında model tarafından yanlış yorumlanmasına da neden olmaktadır.

**2.3.1. Veri Kalitesi Metrikleri ve Değerlendirme Yöntemleri**

Veri kalitesinin sayısal olarak değerlendirilmesi için çok boyutlu bir metrik seti kullanılmaktadır. Etiket tutarlılığı (inter-annotator agreement), aynı örneğe farklı etiketleyicilerin ne ölçüde benzer kararlar verdiğini ölçer; Cohen's kappa (κ) veya Fleiss' kappa gibi istatistiksel ölçütler, rastgele uyumdan ne kadar farklı olduğunu nicelleştirir. Özellik çeşitliliği (feature diversity), veri kümesinin farklı demografik veya bağlamsal grupları kapsayıp kapsamadığını değerlendirir; Shannon entropisi veya Gini çeşitlilik indeksi ile ölçülebilir. Demografik denge (yaş, cinsiyet, etnik köken dağılımı), adil model eğitimi için kritik öneme sahiptir; her demografik grubun temsil oranı, hedef dağılıma yakınlığı ile değerlendirilir. Teknik kalite ölçütleri (örneğin çözünürlük >112x112, bulanıklık ölçütü Laplacian varyansı >100, sinyal-gürültü oranı >20 dB) veri kümesinin güvenilirlik düzeyini belirleyen ek faktörlerdir. Bu göstergelerin her biri, eğitim sürecinde model başarımını farklı yönlerden etkilemekte; dolayısıyla veri kalitesi değerlendirmesi yalnızca etiket doğruluğuna değil, aynı zamanda çeşitlilik, denge ve teknik bütünlüğe de dayandırılmaktadır.

**2.3.2. Çok-Modelli Uzlaşı (Ensemble Agreement) ve Model Uyuşmazlığı**

Bu çalışmada, veri kalitesinin artırılması amacıyla çok-modelli uzlaşı yöntemi CLIP tabanlı anlamsal doğrulama birlikte kullanılmaktadır. Farklı modellerin (örneğin CLIP, YOLO, InsightFace) aynı örnek için benzer tahminler üretmesi o örneğin yüksek güvenilirlik taşıdığını göstermektedir. Buna karşılık, modeller arasında önemli tahmin farkları oluştuğunda, bu durum verinin belirsiz veya hatalı olduğunu işaret etmektedir. Böylece model uyuşmazlığı (model disagreement) bir güvenlik göstergesi olarak işlev görmekte, zayıf veya yanlış etiketlenmiş örneklerin eğitimden elenmesine neden olmaktadır.

Teorik olarak, iki modelin (Buffalo-L ve Custom Age Head) yaş tahminleri arasındaki uzlaşı puanı, mutlak farkın üstel azaltımıyla tanımlanır: C_agreement(x) = exp(-|y₁ - y₂|/σ). Burada σ duyarlılık parametresi olup, σ=2.0 değeri yaş tahmini için makul bir başlangıç noktası sağlar. Üstel azalma fonksiyonu monoton azalan, sürekli ve türevlenebilirdir; büyük farklarda hızlı azalma gösterir. Örneğin 0 yıl fark için C=1.0, 2 yıl için C≈0.368 (σ=2.0), 5 yıl için C≈0.082, 10 yıl için C≈0.007 üretir. Alternatif metrikler (L1 norm, L2 norm, kosinüs benzerliği) de değerlendirilebilir; üstel azalma büyük farklarda daha hızlı ceza, küçük farklarda yumuşak geçiş ve parametrik ayarlanabilirlik avantajları sağlar.

Pratik uygulamada, kod tabanında "çapraz sorgu" (cross-query) yaklaşımı kullanılmaktadır. Buffalo-L tahmini y₁ ve Custom Age Head tahmini y₂ üretilir; her modelin kendi çıktısı için CLIP güveni hesaplanır. Ardından her model diğerinin tahminini doğrular (Buffalo-L, y₂ istemlerine karşı negatif skor elde eder; Custom Head, y₁ istemlerine karşı negatif skor elde eder). Net skorlar (kendi pozitif - karşıt negatif) karşılaştırılır; yüksek net skoru veren seçilir. Eğer her ikisi de düşük güvenle kalırsa Buffalo-L varsayılan olarak kullanılmaktadır. Bu mekanizma, üretimde aşırı uyum riskini sınırlar ve temel model daima güvenli bir geri düşüş noktası olarak kalır.

**2.3.3. CLIP Tabanlı Anlamsal Doğrulama ve Güven Skorlama**

CLIP tabanlı sistemlerde, pozitif ve negatif istemlerle elde edilen benzerlik skorları arasındaki fark (Δ = pos_max - neg_max) normalize edilerek 0–1 aralığında bir güven skoru oluşturulmaktadır. CLIP benzerlik skorları doğrudan 0–100 aralığında üretildiğinden, farkın sigmoid dönüşümüyle olasılık biçimine getirilmesi güvenin sayısallaştırılmasını sağlamaktadır.

CLIP (Contrastive Language-Image Pre-training), metin ve görüntüyü ortak embedding uzayında temsil eder; bu sayede doğal dil ile görsel içerik arasındaki semantik benzerlik ölçülebilir. Görüntü-metin gömülerinin kosinüs benzerliği 0-100 aralığına ölçeklenir: S(I,T) = 100 * cos(E_img(I), E_text(T)). Kosinüs benzerliği iki vektör arasındaki açının kosinüsü olup, 1.0 aynı yön (mükemmel uyum), 0.0 dik açı (ilgisizlik), -1.0 zıt yön (çelişki) anlamına gelir. CLIP modelinde vektörler L2 norm ile birim vektöre dönüştürüldüğü için payda 1 olur ve iç çarpım doğrudan kosinüs değerini verir; bu normalizasyon ölçek bağımsız karşılaştırma sağlar.

Prompt engineering, kategorilere ve yaş aralıklarına özgü istemler tasarlar. Yaş tahmini için pozitif istem: "this face is 35 years old", "this person appears to be 35 years old"; negatif istemler komşu aralıklar: "this face is 18 years old", "this face is 60 years old", "this person looks much younger/older". Her kategori için 5 pozitif, 5 negatif istem tanımlanır. Tokenizer (open_clip.get_tokenizer) istemleri tokenize eder, text encoder embedding'leri üretir, görsel embedding ile kosinüs benzerliği hesaplanır.

CLIP güven skoru hesaplama süreci: (1) Her prompt tokenize edilir, (2) Text encoder ile embedding üretilir, (3) Görüntü CLIP image encoder ile embedding üretilir, (4) Kosinüs benzerliği (similarities = 100.0 * image_features @ text_features.T) hesaplanır, (5) Pozitif skorlar ortalaması ile negatif skorlar ortalaması arasındaki fark (Δ = max(S_pos) - max(S_neg)) hesaplanır. Ham fark sınırsız olabilir; sigmoid normalizasyonu ile [0,1] aralığına taşınır: C_clip(x) = 1 / (1 + exp(-2Δ)). Duyarlılık katsayısı (2), küçük farklarda bile ayrıştırma sağlar; Δ=0'da C=0.5 (belirsiz), Δ=2'de C≈0.982 (yüksek güven), Δ=-2'de C≈0.018 (düşük güven). Final güven 0.1-0.9 ile sınırlandırılır; aşırı uçların etkisi yumuşatılır.

**2.3.4. Model Kalibrasyonu ve Olasılık Dönüşümü**

Modern derin ağların bir diğer önemli sorunu olasılık kalibrasyonudur. Literatürdeki birçok çalışma, ağların sıklıkla "aşırı güvenli" (overconfident) tahminler ürettiğini, örneğin tahmin olasılığı %90 olan bir örneğin gerçekte yalnızca %70 oranında doğru çıktığını göstermiştir (Guo ve diğerleri, 2017). Bu nedenle, modelin çıktı olasılıklarının doğru şekilde kalibre edilmesi, sistem güvenilirliği açısından kritik öneme sahiptir.

En yaygın yöntemlerden sıcaklık ölçeklendirmesi (temperature scaling), softmax fonksiyonuna sıcaklık parametresi (T) ekleyerek olasılık dağılımını yumuşatır; T>1 değerleri daha düşük güvenli, T<1 değerleri ise daha keskin olasılıklar üretir. Alternatif bir yöntem olan Platt ölçeklendirmesi, doğrulama kümesi üzerinde lojistik regresyon eğitilerek kalibrasyon parametrelerini öğrenir (Lin ve diğerleri, 2007). İzotonik regresyon (isotonic regression), monotonik bir dönüşüm sağlar ve sıralamayı korur; küçük ve orta boy veri kümelerinde Platt scaling'den daha esnek olabilir.

Expected Calibration Error (ECE), kalibrasyon kalitesini ölçmek için yaygın olarak kullanılan bir metrikdir. Tahminler güven aralıklarına bölünür (örn. [0.0-0.1], [0.1-0.2], ..., [0.9-1.0]); her aralıkta ortalama güven ile gerçek doğruluk farkının ağırlıklı ortalaması hesaplanır. Düşük ECE daha iyi kalibrasyon demektir. Reliability diagram (güvenilirlik diyagramı), her güven aralığındaki ortalama tahmin olasılığı ile gerçek doğruluk oranını görselleştirir; ideal kalibrasyonda diyagonal bir çizgi oluşur.

Bu çalışmada kullanılan güven skorları (CLIP tabanlı anlamsal doğrulama ve çok-modelli uzlaşı) doğrudan bir "olasılık" değildir; yine de karar eşiği seçimi ve veri seçimi süreçlerinde kalibrasyon ilkeleri dikkate alınır. Gelecek çalışmalarda, ROC/PR eşik taraması ve ECE ölçümü ile birlikte eşik optimizasyonu gerçekleştirilebilir.

**2.3.5. Eşik Değeri Seçimi ve ROC/PR Eğrileri**

Eşik değeri seçimi, kalibrasyon sürecinin ayrılmaz bir parçasıdır. Bu çalışma kapsamında eşik optimizasyonu, ROC (Receiver Operating Characteristic) ve PR (Precision–Recall) eğrileri üzerinden gerçekleştirilmiştir. ROC eğrisi, gerçek pozitif oranı (TPR = TP/(TP+FN)) ile yanlış pozitif oranı (FPR = FP/(FP+TN)) arasındaki ilişkiyi gösterirken PR eğrisi ise hassasiyet (precision = TP/(TP+FP)) ve geri çağırma (recall = TP/(TP+FN)) dengesini sunar (Davis ve Goadrich, 2006). 

Özellikle dengesiz veri kümelerinde (örneğin pozitif örneklerin %5'ten az olduğu senaryolar), ROC eğrisi yanıltıcı sonuçlar verebilir. Bu nedenle PR eğrisi daha bilgilendirici bir ölçüt olarak tercih edilmiştir. Çok düşük eşik değerleri (örneğin 0.3), sisteme gürültülü verilerin dahil olmasına ve yanlış pozitif oranının artmasına yol açarken, aşırı yüksek eşikler (örneğin 0.95) pozitif örneklerin elenmesine, dolayısıyla veri çeşitliliğinin azalmasına neden olmaktadır. Bu denge noktasını belirlemek amacıyla basit birkaç deneme yapılmış ve optimum güven eşiği τ=0.75 olarak deneysel biçimde belirlenmiştir.

Üç aşamalı karar kuralı uygulanır: (1) Yüksek güven (C_final ≥ 0.75): Eğitimde kullanılacak yüksek kaliteli örnekler; Feedback tablosuna pseudo türüyle kaydedilir, training_status="pending" olarak işaretlenir, otomatik eğitim kuyruğuna alınır. (2) Orta güven (0.5 ≤ C_final < 0.75): İnsan gözden geçirme kuyruğu; manuel etiketleme için bekletilir, kullanıcıya overlay görseli ve tahmin sunulur, kullanıcı onayı sonrası eğitime dahil edilir. (3) Düşük güven (C_final < 0.5): Dışlanır, eğitime alınmaz; depolama tasarrufu sağlanır, gelecekteki model güncellemelerinde yeniden değerlendirilir. Bu strateji, insan-döngüde gözden geçirme (human-in-the-loop review) yaklaşımının doğrudan uygulamasıdır.

**2.3.6. Gürültülü Veri Tespiti ve Temizleme Stratejileri**

Gürültülü etiketlerin tespiti ve temizlenmesi, veri kalitesi artırımının kritik bir bileşenidir. Confident Learning yaklaşımı, sınıf koşullu gürültü matrisini istatistiksel olarak modelleyerek hatalı örnekleri tanımlar ve veri temizliği sağlar (Northcutt ve diğerleri, 2021). Gürültülü etiketli eğitim dinamikleri, erken öğrenme etkisini (temiz örneklerin başta öğrenilmesi) ve örnek seçimi/ağırlıklandırma taktiklerini destekler (Chen ve diğerleri, 2019). 

Bu çalışmada benzer ilke, örnek-bazlı ağırlıklı MSE kaybı ile uygulanır; yüksek CLIP güvenli örnekler eğitime daha fazla katkı sağlar. Tahmin uyuşmazlığı sinyallerinin seçim ve ağırlıklandırmaya rehberlik ettiğini gösteren çalışmalar, gürültülü gözetimde genellemeyi iyileştirir (Yu ve diğerleri, 2019); bu çalışmada Buffalo-L ve Custom Age Head uyuşmazlığı düşük güven işareti olur, çapraz-test ile en güvenilir seçilir.

**2.3.7. Veri Seçimi Stratejileri ve Active Learning**

Active learning, en bilgilendirici örneklerin seçilerek etiketleme maliyetini minimize eden bir yaklaşımdır. Uncertainty sampling, modelin en belirsiz olduğu örnekleri seçer; entropy tabanlı veya margin tabanlı ölçütler kullanılabilir. Query-by-committee, birden fazla modelin en çok anlaşmazlık gösterdiği örnekleri seçer; bu çalışmada Buffalo-L ve Custom Head arasındaki uyuşmazlık bu yaklaşımın bir örneğidir. Diversity sampling, veri çeşitliliğini korumak için farklı örnekler seçer; k-means clustering veya core-set selection yöntemleri kullanılabilir.

Bu çalışmada, güven skorlarına dayalı otomatik veri seçimi uygulanmaktadır. Yüksek güvenli örnekler (C_final ≥ 0.75) otomatik olarak eğitime dahil edilirken, orta güvenli örnekler (0.5 ≤ C_final < 0.75) insan gözden geçirmesi için bekletilir. Bu yaklaşım, active learning'in bir varyantı olarak görülebilir; belirsiz örnekler insan etiketçiye yönlendirilirken, yüksek güvenli örnekler otomatik olarak kullanılır.

**2.3.8. Dağılım Kaymaları ve Adaptasyon**

Dağılım kaymaları (distribution shift), model performansını belirgin biçimde etkileyen bir faktördür. Covariate shift (girdi dağılımı), test verisinin eğitim verisinden farklı bir dağılıma sahip olması durumudur; örneğin farklı kamera açıları, ışık koşulları veya demografik gruplar. Label shift (sınıf öncülleri), sınıf dağılımının değişmesi durumudur; örneğin eğitimde genç bireyler daha fazlayken testte yaşlı bireyler daha fazla olabilir. Concept drift (hedef kavram), tahmin edilmek istenen kavramın zamanla değişmesi durumudur; örneğin "genç" kavramının toplumsal normlara göre değişmesi. Temporal drift (zaman), zaman içinde veri dağılımının değişmesi durumudur; örneğin mevsimsel değişiklikler veya teknolojik gelişmeler.

Bu çalışmada, kişi-bazlı ayrık bölünme (person-based disjoint split) ve sürümleme notlarıyla dağılım kaymalarının etkileri izlenmekte ve azaltılmaktadır. Periyodik eşik taraması, gelecek çalışmalarda eşik değerlerinin periyodik olarak yeniden değerlendirilmesi ve güncellenmesi planlanmaktadır. Gürültülü etiketler, pseudo-label'larda güven eşiği (τ≈0.75) ve örnek-ağırlıklı kayıp ile etkisi düşürülür; manuel geri bildirim birincil kabul edilir ve tekrar kullanım engellenir.

**2.3.9. Demografik Denge ve Önyargı Kontrolü**

Demografik denge ve önyargı kontrolü, seçilen örneklerin yaş dağılımını izler. Her yaş bandında (0-10, 11-20, 21-30, 31-40, 41-50, 51+) hedef yüzdeye ulaşılması kontrol edilir; uç bantlar (0-5, 70+) yetersiz temsil ediliyorsa stratified örnekleme veya eşik ayarlaması (τ-0.05) uygulanır. Kişi bazlı tekilleştirme, aynı person_id için en güncel manual feedback'i tercih eder; pseudo-label tekrarları elenir. Embedding benzerliği >0.95 olan örnekler tekrar olarak işaretlenir; en yüksek güven skorlu korunur.

**2.3.10. Audit Log ve İzlenebilirlik**

Audit log yapısı, her seçim kararını kaydeder: timestamp, sample_id, clip_confidence, agreement_score, final_confidence, threshold, decision, reason, model_version, demographic_info (age_band, gender). Bu kayıtlar sürdürülebilirlik, yeniden üretilebilirlik, şeffaflık, performans analizi ve yasal uyumluluk sağlar. Gelecekteki model güncellemelerinde, bu loglar kullanılarak eşik değerlerinin optimizasyonu ve veri seçimi stratejilerinin iyileştirilmesi mümkündür.



