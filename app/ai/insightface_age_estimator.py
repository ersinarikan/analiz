import insightface
import numpy as np
import cv2
import os
import torch
import logging
from PIL import Image  # PIL kÃ¼tÃ¼phanesini ekliyoruz
from flask import current_app # current_app import edildi
import time

# Logger oluÅŸtur
logger = logging.getLogger(__name__)

# CustomAgeHead sÄ±nÄ±fÄ± (train_v1.py'den alÄ±nmalÄ±)
class CustomAgeHead(torch.nn.Module):
    def __init__(self, input_dim=512, hidden_dims=[256, 128], output_dim=1, input_size=None):
        super().__init__()
        # input_size parametresi varsa onu kullan (backward compatibility iÃ§in)
        if input_size is not None:
            input_dim = input_size
        
        layers = []
        prev_dim = input_dim
        for hidden_dim in hidden_dims:
            layers.append(torch.nn.Linear(prev_dim, hidden_dim))
            layers.append(torch.nn.ReLU())
            prev_dim = hidden_dim
        layers.append(torch.nn.Linear(prev_dim, output_dim))
        self.network = torch.nn.Sequential(*layers)

    def forward(self, x):
        return self.network(x)

# Versiyonlu model bulucu fonksiyon
def find_latest_age_model(model_path):
    age_model_dir = os.path.join(model_path, 'models') # veya doÄŸrudan model_path altÄ±nda olabilir
    if not os.path.isdir(age_model_dir):
        logger.warning(f"YaÅŸ modeli iÃ§in 'models' klasÃ¶rÃ¼ bulunamadÄ±: {age_model_dir}")
        return None
    
    model_files = [f for f in os.listdir(age_model_dir) if f.startswith('age_model_epoch_') and f.endswith('.pth')]
    if not model_files:
        logger.warning(f"'models' klasÃ¶rÃ¼nde Ã¶zel yaÅŸ modeli bulunamadÄ±: {age_model_dir}")
        return None
    
    # Epoch numarasÄ±na gÃ¶re sÄ±rala ve en sonuncuyu al
    model_files.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]), reverse=True)
    latest_model_file = model_files[0]
    logger.info(f"Bulunan en son Ã¶zel yaÅŸ modeli: {latest_model_file}")
    return os.path.join(age_model_dir, latest_model_file)

class InsightFaceAgeEstimator:
    def __init__(self, det_size=(1024, 1024)):
        # Model dosya yolunu ayarla
        # active_insightface_path = os.path.join(Config.MODELS_FOLDER, 'age', 'buffalo_l') # Eski yol
        active_insightface_path = current_app.config['INSIGHTFACE_AGE_MODEL_ACTIVE_PATH']
        base_insightface_path = current_app.config['INSIGHTFACE_AGE_MODEL_BASE_PATH']

        # Insightface modelini yÃ¼klemek iÃ§in kullanÄ±lacak asÄ±l yol
        # Ã–nce active_model'i kontrol et, eÄŸer boÅŸsa veya gerekli dosyalar yoksa base_model'i kullan.
        # insightface.app.FaceAnalysis, root parametresinde model dosyalarÄ±nÄ± (Ã¶rn: detection.onnx, genderage.onnx) bekler.
        insightface_root_to_load = active_insightface_path
        # Basit bir kontrol: active_model altÄ±nda bir ÅŸeyler var mÄ±?
        # Daha iyi bir kontrol, belirli .onnx dosyalarÄ±nÄ±n varlÄ±ÄŸÄ±nÄ± kontrol etmek olabilir.
        # detection.onnx yerine buffalo_l modelinin kullandÄ±ÄŸÄ± det_10g.onnx dosyasÄ±nÄ± kontrol edelim.
        if not os.path.exists(os.path.join(active_insightface_path, 'det_10g.onnx')):
            logger.warning(f"Aktif InsightFace modeli ({active_insightface_path}) tam deÄŸil veya bulunamadÄ± (det_10g.onnx eksik). Base model ({base_insightface_path}) denenecek.")
            insightface_root_to_load = base_insightface_path
            if not os.path.exists(os.path.join(insightface_root_to_load, 'det_10g.onnx')):
                 logger.error(f"Base InsightFace modeli de ({insightface_root_to_load}) yÃ¼klenemiyor. 'det_10g.onnx' bulunamadÄ±.")
                 raise FileNotFoundError(f"InsightFace 'det_10g.onnx' dosyasÄ± ne aktif ne de base path'te bulunamadÄ±.")

        logger.info(f"InsightFaceAgeEstimator baÅŸlatÄ±lÄ±yor. Model iÃ§in kullanÄ±lacak root: {insightface_root_to_load}")
        
        # Log the contents of the directory that will be passed to FaceAnalysis
        if os.path.exists(insightface_root_to_load):
            logger.info(f"'{insightface_root_to_load}' klasÃ¶rÃ¼nÃ¼n iÃ§eriÄŸi: {os.listdir(insightface_root_to_load)}")
        else:
            logger.warning(f"'{insightface_root_to_load}' klasÃ¶rÃ¼ bulunamadÄ±.")

        # FACE_DETECTION_CONFIDENCE deÄŸerini config'den oku
        # FACTORY_DEFAULTS'taki deÄŸer 0.5, kodda kullanÄ±lan 0.2 idi.
        # Config'den gelen deÄŸer Ã¶ncelikli olacak.
        face_detection_thresh = current_app.config.get('FACE_DETECTION_CONFIDENCE', 0.5) 
        logger.info(f"KullanÄ±lacak yÃ¼z tespit eÅŸiÄŸi (det_thresh): {face_detection_thresh}")

        # Modeli yerel dosyadan yÃ¼kle
        try:
            # Prefer GPU execution provider if available (requires onnxruntime-gpu)
            try:
                import onnxruntime as ort  # type: ignore
                available = set(ort.get_available_providers() or [])
            except Exception:
                available = set()

            providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if 'CUDAExecutionProvider' in available else ['CPUExecutionProvider']
            ctx_id = 0 if 'CUDAExecutionProvider' in providers else -1
            logger.info(f"InsightFace providers: {providers} (ctx_id={ctx_id})")

            self.model = insightface.app.FaceAnalysis(
                name='buffalo_l', # Bu isim, root iÃ§indeki alt klasÃ¶rlerle eÅŸleÅŸebilir veya sadece genel bir addÄ±r.
                root=insightface_root_to_load, # GÃ¼ncellenmiÅŸ yol
                providers=providers,
                det_thresh=face_detection_thresh # Dinamik olarak okunan deÄŸeri kullan
            )
            self.model.prepare(ctx_id=ctx_id, det_size=det_size)
            logger.info(f"InsightFace temel modeli baÅŸarÄ±yla yÃ¼klendi (det_thresh={face_detection_thresh} ile)")
        except Exception as e:
            logger.error(f"InsightFace model yÃ¼kleme hatasÄ±: {str(e)}")
            raise
        
        # Custom Age Head modelini yÃ¼kle
        self.device = torch.device("cuda" if torch.cuda.is_available() and current_app.config.get('USE_GPU', True) else "cpu")
        self.custom_age_head = None
        
        # Performance optimization flags
        self.initialized = True
        self._last_cleanup = time.time()
        self._memory_threshold_mb = 14000  # Memory cleanup threshold (14GB - GPU memory'nin %85'i, Ã§ok agresif cleanup'Ä± Ã¶nler)
        
        # Model load and initialize tracking for performance
        logger.info(f"InsightFaceAgeEstimator device: {self.device}")
        
        try:
            # Ã–nce active_model'den yÃ¼klemeye Ã§alÄ±ÅŸ
            custom_age_head_dir = os.path.join(current_app.config['MODELS_FOLDER'], 'age', 'custom_age_head', 'active_model')
            
            # active_model bir sembolik link olabilir, gerÃ§ek dizini kontrol et
            if os.path.islink(custom_age_head_dir):
                custom_age_head_dir = os.path.realpath(custom_age_head_dir)
            
            if not os.path.exists(custom_age_head_dir):
                # EÄŸer active_model yoksa base_model'den yÃ¼kle
                custom_age_head_dir = os.path.join(current_app.config['MODELS_FOLDER'], 'age', 'custom_age_head', 'base_model')
            
            if os.path.exists(custom_age_head_dir):
                # .pth dosyasÄ±nÄ± bul (model.pth veya custom_age_head.pth olabilir)
                pth_files = [f for f in os.listdir(custom_age_head_dir) if f.endswith('.pth')]
                if pth_files:
                    model_path = os.path.join(custom_age_head_dir, pth_files[0])
                    logger.info(f"CustomAgeHead model dosyasÄ± bulundu: {model_path}")
                    try:
                        # Model checkpoint'ini yÃ¼kle
                        checkpoint = torch.load(model_path, map_location='cpu', weights_only=True)
                        
                        # Model konfigÃ¼rasyonunu al
                        if 'model_config' in checkpoint:
                            model_config = checkpoint['model_config']
                            self.custom_age_head = CustomAgeHead(
                                input_dim=model_config['input_dim'],
                                hidden_dims=model_config['hidden_dims'],
                                output_dim=model_config['output_dim']
                            )
                        else:
                            # VarsayÄ±lan konfigÃ¼rasyon
                            self.custom_age_head = CustomAgeHead(input_dim=512, hidden_dims=[256, 128], output_dim=1)
                        
                        # Model aÄŸÄ±rlÄ±klarÄ±nÄ± yÃ¼kle
                        if 'model_state_dict' in checkpoint:
                            self.custom_age_head.load_state_dict(checkpoint['model_state_dict'])
                        else:
                            # Eski formatta kaydedilmiÅŸ olabilir
                            self.custom_age_head.load_state_dict(checkpoint)
                        
                        self.custom_age_head.eval()  # Evaluation moduna geÃ§
                        self.custom_age_head.to(self.device)
                        logger.info(f"CustomAgeHead baÅŸarÄ±yla {model_path} yolundan {self.device} Ã¼zerinde yÃ¼klendi.")
                        
                        # Eski uyumluluk iÃ§in age_model alias'Ä±
                        self.age_model = self.custom_age_head
                        
                    except Exception as e:
                        logger.error(f"CustomAgeHead yÃ¼klenirken hata: {str(e)}")
                        self.custom_age_head = None
                        self.age_model = None
                else:
                    logger.warning(f"CustomAgeHead model dosyasÄ± (.pth) bulunamadÄ±: {custom_age_head_dir}")
                    self.custom_age_head = None
                    self.age_model = None
            else:
                logger.warning(f"CustomAgeHead model dizini bulunamadÄ±: {custom_age_head_dir}")
                self.custom_age_head = None
                self.age_model = None
                
        except Exception as e:
            logger.error(f"Custom Age Head model yÃ¼kleme hatasÄ±: {str(e)}")
            self.custom_age_head = None
            self.age_model = None
            
        # CLIP modelini yÃ¼kle - ama Ã¶nce shared CLIP kontrol et
        self.clip_model = None
        self.clip_preprocess = None 
        self.tokenizer = None
        self.clip_device = "cpu"
        
        logger.info("âš ï¸ CLIP yÃ¼kleme skip edildi - ContentAnalyzer'dan shared CLIP beklenecek")
        logger.info("ğŸ”„ set_shared_clip() metodu ile CLIP inject edilecek")

    def cleanup_models(self):
        """GPU memory ve model referanslarÄ±nÄ± temizle - Performance optimization"""
        try:
            logger.info("InsightFaceAgeEstimator cleanup baÅŸlatÄ±lÄ±yor...")
            
            # CLIP model temizle
            if hasattr(self, 'clip_model') and self.clip_model is not None:
                del self.clip_model
                self.clip_model = None
                logger.debug("CLIP model cleaned up")
            
            if hasattr(self, 'clip_preprocess') and self.clip_preprocess is not None:
                del self.clip_preprocess
                self.clip_preprocess = None
                logger.debug("CLIP preprocess cleaned up")
                
            # Custom age head temizle
            if hasattr(self, 'custom_age_head') and self.custom_age_head is not None:
                del self.custom_age_head
                self.custom_age_head = None
                logger.debug("Custom age head cleaned up")
                
            # InsightFace model temizle
            if hasattr(self, 'model') and self.model is not None:
                del self.model
                self.model = None
                logger.debug("InsightFace model cleaned up")
                
            # Tokenizer temizle
            if hasattr(self, 'tokenizer') and self.tokenizer is not None:
                del self.tokenizer
                self.tokenizer = None
                logger.debug("Tokenizer cleaned up")
                
            # GPU cache temizle
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                logger.debug("GPU cache cleaned up")
                
            # Update cleanup timestamp
            self._last_cleanup = time.time()
            logger.info("InsightFaceAgeEstimator cleanup tamamlandÄ±")
            
        except Exception as e:
            logger.warning(f"InsightFaceAgeEstimator cleanup sÄ±rasÄ±nda hata: {e}")
    
    def set_shared_clip(self, clip_model, clip_preprocess=None, tokenizer=None):
        """
        ContentAnalyzer'dan CLIP modelini paylaÅŸ - Memory optimization
        
        Args:
            clip_model: ContentAnalyzer'Ä±n CLIP modeli
            clip_preprocess: CLIP preprocessing fonksiyonu  
            tokenizer: CLIP tokenizer
        """
        try:
            logger.info("Shared CLIP model InsightFaceAgeEstimator'a inject ediliyor...")
            
            # Mevcut CLIP modelini temizle
            if hasattr(self, 'clip_model') and self.clip_model is not None:
                logger.debug("Mevcut CLIP model temizleniyor...")
                del self.clip_model
                self.clip_model = None
            
            # Shared CLIP modelini ayarla
            self.clip_model = clip_model
            self.clip_preprocess = clip_preprocess
            self.tokenizer = tokenizer
            
            # Device bilgisini gÃ¼ncelle
            if hasattr(clip_model, 'device') and clip_model.device:
                self.clip_device = clip_model.device
            else:
                self.clip_device = next(clip_model.parameters()).device if clip_model else "cpu"
            
            logger.info(f"âœ… Shared CLIP model baÅŸarÄ±yla inject edildi! Device: {self.clip_device}")
            
        except Exception as e:
            logger.error(f"Shared CLIP model inject hatasÄ±: {e}")
            self.clip_model = None
            self.clip_preprocess = None
            self.tokenizer = None
    
    def __del__(self):
        """Garbage collection sÄ±rasÄ±nda cleanup yap"""
        try:
            if hasattr(self, 'initialized') and self.initialized:
                self.cleanup_models()
        except:
            pass  # Ignore errors during garbage collection

    def _check_memory_usage(self):
        """Memory usage kontrolÃ¼ ve otomatik cleanup - Performance monitoring"""
        try:
            current_time = time.time()
            # Her 5 dakikada bir memory kontrolÃ¼ yap
            if current_time - self._last_cleanup > 300:  # 5 minutes
                
                # GPU memory kontrolÃ¼
                if torch.cuda.is_available():
                    gpu_memory_mb = torch.cuda.memory_allocated() / (1024 * 1024)
                    if gpu_memory_mb > self._memory_threshold_mb:
                        logger.warning(f"High GPU memory usage detected: {gpu_memory_mb:.1f}MB, triggering cleanup")
                        torch.cuda.empty_cache()
                        self._last_cleanup = current_time
                
        except Exception as e:
            logger.debug(f"Memory check error: {e}")

    def estimate_age(self, full_image: np.ndarray, face):
        """
        Verilen 'face' nesnesi iÃ§in yaÅŸ tahminini ve CLIP gÃ¼ven skorunu dÃ¶ndÃ¼rÃ¼r.
        YÃ¼z tespiti bu fonksiyonda *yapÄ±lmaz*, Ã¶nceden tespit edilmiÅŸ face nesnesi kullanÄ±lÄ±r.

        Args:
            full_image (np.ndarray): YÃ¼zÃ¼n bulunduÄŸu orijinal tam kare (BGR).
            face: InsightFace modelinin get() metodundan dÃ¶nen yÃ¼z nesnesi.

        Returns:
            Tuple: (final_age, final_confidence, pseudo_label_data_to_save)
                   pseudo_label_data_to_save bir dict veya None olabilir.
        """
        # Performance monitoring
        self._check_memory_usage()
        
        if face is None:
            logger.warning("estimate_age: GeÃ§ersiz 'face' nesnesi alÄ±ndÄ± (None). VarsayÄ±lan deÄŸerler dÃ¶nÃ¼lÃ¼yor.")
            return 25.0, 0.5, None

        logger.info(f"[AGE_LOG] estimate_age baÅŸladÄ±. Gelen face bbox: {face.bbox}, Ham InsightFace YaÅŸÄ±: {face.age}")

        # AdÄ±m 1: Temel Bilgileri Topla
        embedding_current = face.embedding if hasattr(face, 'embedding') and face.embedding is not None else None
        age_buffalo_raw = face.age # Bu buffalo_l'nin ONNX modelinden gelen ham yaÅŸ

        if age_buffalo_raw is None:
            logger.warning("[AGE_LOG] InsightFace (Buffalo) ham yaÅŸÄ± None, varsayÄ±lan (25.0) kullanÄ±lacak.")
            age_buffalo_raw = 25.0
        
        age_buffalo = float(age_buffalo_raw) # TutarlÄ±lÄ±k iÃ§in float yapalÄ±m

        # AdÄ±m 1.1: CLIP iÃ§in YÃ¼z ROI Ã‡Ä±kar
        face_roi = None
        try:
            x1, y1, x2, y2 = [int(v) for v in face.bbox]
            h_img, w_img = full_image.shape[:2]
            x1 = max(0, x1)
            y1 = max(0, y1)
            x2 = min(w_img, x2)
            y2 = min(h_img, y2)
            if x2 > x1 and y2 > y1:
                 face_roi = full_image[y1:y2, x1:x2]
            else:
                 logger.warning(f"[AGE_LOG] estimate_age: GeÃ§ersiz bbox koordinatlarÄ± nedeniyle face_roi Ã§Ä±karÄ±lamadÄ±: x1={x1}, y1={y1}, x2={x2}, y2={y2}")
        except Exception as e:
            logger.error(f"[AGE_LOG] face_roi Ã§Ä±karÄ±lÄ±rken hata: {str(e)}")

        if face_roi is None:
             logger.warning("[AGE_LOG] face_roi yok, CLIP tabanlÄ± karÅŸÄ±laÅŸtÄ±rma yapÄ±lamÄ±yor. Buffalo ham tahmini ({age_buffalo:.1f}) ve varsayÄ±lan gÃ¼ven (0.5) dÃ¶nÃ¼lÃ¼yor.")
             # SÃ¶zde etiket verisi de None olmalÄ± Ã§Ã¼nkÃ¼ CLIP gÃ¼veni yok
             return age_buffalo, 0.5, None

        # AdÄ±m 2: Buffalo_l Tahmini iÃ§in CLIP GÃ¼venini Hesapla
        logger.info(f"[AGE_LOG] Buffalo ham tahmini ({age_buffalo:.1f}) iÃ§in CLIP gÃ¼veni hesaplanÄ±yor...")
        confidence_clip_buffalo = self._calculate_confidence_with_clip(face_roi, age_buffalo)
        logger.info(f"[AGE_LOG] Buffalo Ham YaÅŸÄ±nÄ±n CLIP GÃ¼veni: {confidence_clip_buffalo:.4f}")

        # AdÄ±m 3: CustomAgeHead Tahmini ve CLIP GÃ¼venini Hesapla (EÄŸer MÃ¼mkÃ¼nse)
        age_custom = None
        confidence_clip_custom = -1.0 # KarÅŸÄ±laÅŸtÄ±rmada dÃ¼ÅŸÃ¼k kalmasÄ± iÃ§in baÅŸlangÄ±Ã§ deÄŸeri
        custom_age_calculated = False

        if self.age_model is not None and embedding_current is not None:
            try:
                with torch.no_grad():
                    emb_tensor = torch.tensor(embedding_current, dtype=torch.float32).unsqueeze(0).to(self.device)
                    # NORMALIZE EMBEDDING (Custom model eÄŸitimi sÄ±rasÄ±nda eksik olan adÄ±m)
                    emb_tensor = emb_tensor / torch.norm(emb_tensor, dim=1, keepdim=True)
                    age_custom_pred = self.age_model(emb_tensor).item()
                logger.info(f"[AGE_LOG] Ã–zel yaÅŸ modeli (CustomAgeHead) tahmini: {age_custom_pred:.1f}")
                age_custom = float(age_custom_pred) # float yap
                logger.info(f"[AGE_LOG] CustomAgeHead tahmini ({age_custom:.1f}) iÃ§in CLIP gÃ¼veni hesaplanÄ±yor...")
                confidence_clip_custom = self._calculate_confidence_with_clip(face_roi, age_custom)
                logger.info(f"[AGE_LOG] CustomAgeHead Tahmininin CLIP GÃ¼veni: {confidence_clip_custom:.4f}")
                custom_age_calculated = True
            except Exception as e:
                logger.error(f"[AGE_LOG] Ã–zel yaÅŸ modeli (CustomAgeHead) ile tahmin veya CLIP gÃ¼veni hesaplanÄ±rken hata: {str(e)}")
        elif self.age_model is None:
            logger.info("[AGE_LOG] Ã–zel yaÅŸ modeli (CustomAgeHead) yÃ¼klenmemiÅŸ.")
        elif embedding_current is None:
            logger.info("[AGE_LOG] Ã–zel yaÅŸ modeli (CustomAgeHead) iÃ§in embedding mevcut deÄŸil (face.embedding None).")

        # AdÄ±m 4: Nihai YaÅŸ ve GÃ¼ven Belirleme (CLIP GÃœVEN SKORLARINA GÃ–RE)
        final_age = age_buffalo # VarsayÄ±lan olarak buffalo'nun ham yaÅŸÄ±
        final_confidence = confidence_clip_buffalo # ve onun CLIP gÃ¼veni
        
        # CLIP TABANLI BASÄ°T SEÃ‡Ä°M: CLIP'in hangi tahmine daha yÃ¼ksek gÃ¼ven verdiÄŸine bak
        if custom_age_calculated:
            # CLIP gÃ¼ven skorlarÄ± Ã§ok dÃ¼ÅŸÃ¼kse (0.15) Ã¶zel mantÄ±k uygula
            LOW_CONFIDENCE_THRESHOLD = 0.15
            both_low_confidence = confidence_clip_buffalo <= LOW_CONFIDENCE_THRESHOLD and confidence_clip_custom <= LOW_CONFIDENCE_THRESHOLD
            
            if both_low_confidence:
                # Her iki model de dÃ¼ÅŸÃ¼k gÃ¼venle tahmin yapÄ±yor
                # Ã‡ocuklar iÃ§in daha kÃ¼Ã§Ã¼k yaÅŸÄ± tercih et, bÃ¼yÃ¼k fark varsa
                age_diff = abs(age_buffalo - age_custom)
                if age_diff > 5:  # BÃ¼yÃ¼k fark varsa
                    # Daha kÃ¼Ã§Ã¼k yaÅŸÄ± tercih et (Ã§ocuklar iÃ§in daha mantÄ±klÄ±)
                    if age_custom < age_buffalo:
                        final_age = age_custom
                        final_confidence = confidence_clip_custom
                        logger.info(f"[AGE_LOG][LOW_CONF_SELECT] Her iki model dÃ¼ÅŸÃ¼k gÃ¼ven, CustomAgeHead seÃ§ildi (daha kÃ¼Ã§Ã¼k yaÅŸ: {age_custom:.1f} vs {age_buffalo:.1f})")
                    else:
                        final_age = age_buffalo
                        final_confidence = confidence_clip_buffalo
                        logger.info(f"[AGE_LOG][LOW_CONF_SELECT] Her iki model dÃ¼ÅŸÃ¼k gÃ¼ven, Buffalo seÃ§ildi (daha kÃ¼Ã§Ã¼k yaÅŸ: {age_buffalo:.1f} vs {age_custom:.1f})")
                else:
                    # Fark kÃ¼Ã§Ã¼kse, Buffalo'yu tercih et (daha baÅŸarÄ±lÄ±)
                    final_age = age_buffalo
                    final_confidence = confidence_clip_buffalo
                    logger.info(f"[AGE_LOG][LOW_CONF_SELECT] Her iki model dÃ¼ÅŸÃ¼k gÃ¼ven, Buffalo seÃ§ildi (fark kÃ¼Ã§Ã¼k: {age_diff:.1f})")
            else:
                # Normal seÃ§im: CLIP'in hangi tahmine daha yÃ¼ksek gÃ¼ven verdiÄŸine bak
                if confidence_clip_custom > confidence_clip_buffalo:
                    final_age = age_custom
                    final_confidence = confidence_clip_custom
                    logger.info(f"[AGE_LOG][CLIP_SELECT] CustomAgeHead seÃ§ildi (CLIP gÃ¼veni daha yÃ¼ksek: {confidence_clip_custom:.4f} > {confidence_clip_buffalo:.4f})")
                elif confidence_clip_custom < confidence_clip_buffalo:
                    final_age = age_buffalo  
                    final_confidence = confidence_clip_buffalo
                    logger.info(f"[AGE_LOG][CLIP_SELECT] Buffalo seÃ§ildi (CLIP gÃ¼veni daha yÃ¼ksek: {confidence_clip_buffalo:.4f} > {confidence_clip_custom:.4f})")
                else:
                    # EÅŸitlik durumunda: Buffalo'yu tercih et (daha baÅŸarÄ±lÄ±)
                    final_age = age_buffalo  
                    final_confidence = confidence_clip_buffalo
                    logger.info(f"[AGE_LOG][CLIP_SELECT] CLIP gÃ¼ven skorlarÄ± eÅŸit ({confidence_clip_buffalo:.4f}), Buffalo tercih edildi")
        
        # AdÄ±m 5: CustomAgeHead Ä°Ã§in Potansiyel SÃ¶zde Etiketli Veri HazÄ±rlama
        pseudo_label_data_to_save = None
        RECORD_THRESHOLD = current_app.config.get('PSEUDO_LABEL_RECORD_CLIP_THRESHOLD', 0.75) 

        # SÃ¶zde etiket iÃ§in buffalo_l'nin kendi ham tahmini ve onun CLIP gÃ¼venini kullan
        # Dikkat: Burada final_confidence deÄŸil, confidence_clip_buffalo kullanÄ±lmalÄ±!
        if confidence_clip_buffalo >= RECORD_THRESHOLD:
            logger.info(f"[DATA_LOG] Buffalo ham tahmini (YaÅŸ: {age_buffalo:.1f}, CLIP GÃ¼veni: {confidence_clip_buffalo:.4f}) CustomAgeHead iÃ§in potansiyel eÄŸitim verisi olarak hazÄ±rlanÄ±yor (EÅŸik: {RECORD_THRESHOLD}).")
            bbox_str = ",".join(map(str, [int(v) for v in face.bbox])) 
            emb = embedding_current
            if emb is not None:
                if hasattr(emb, 'tolist'):
                    emb_str = ",".join(str(float(x)) for x in emb.tolist())
                elif isinstance(emb, (list, tuple)):
                    emb_str = ",".join(str(float(x)) for x in emb)
                else:
                    emb_str = str(emb)
            else:
                emb_str = None
            pseudo_label_data_to_save = {
                "face_bbox": bbox_str,
                "embedding": emb_str, # ArtÄ±k string olarak
                "pseudo_label_original_age": age_buffalo, # Buffalo'nun ham yaÅŸ tahmini
                "pseudo_label_clip_confidence": confidence_clip_buffalo, # Buffalo'nun yaÅŸÄ±nÄ±n CLIP gÃ¼veni
                "feedback_source": "PSEUDO_BUFFALO_HIGH_CONF",
                "feedback_type": "age_pseudo"
                # frame_path, content_id, analysis_id, person_id gibi bilgiler servis katmanÄ±nda eklenecek
            }
            if embedding_current is None: # embedding_current yukarÄ±da zaten None ise buraya girmez ama yine de kontrol
                 logger.warning("[DATA_LOG] SÃ¶zde etiket iÃ§in embedding (embedding_current) mevcut deÄŸil, bu bilgi eksik olacak.")

        logger.info(f"[AGE_LOG][DETAIL] Buffalo yaÅŸ tahmini: {age_buffalo:.2f}, CLIP gÃ¼veni: {confidence_clip_buffalo:.4f}")
        if custom_age_calculated:
            logger.info(f"[AGE_LOG][DETAIL] CustomAgeHead yaÅŸ tahmini: {age_custom:.2f}, CLIP gÃ¼veni: {confidence_clip_custom:.4f}")
        else:
            logger.info(f"[AGE_LOG][DETAIL] CustomAgeHead tahmini yapÄ±lamadÄ±.")
        logger.info(f"[AGE_LOG][SELECT] SeÃ§ilen yaÅŸ tahmini: {final_age:.2f}, CLIP gÃ¼veni: {final_confidence:.4f}")
        if pseudo_label_data_to_save:
            logger.info(f"[AGE_LOG][PSEUDO] Pseudo label kaydÄ± hazÄ±rlanacak: {pseudo_label_data_to_save}")

        logger.info(f"[AGE_LOG] estimate_age tamamlandÄ±. DÃ¶nen Nihai YaÅŸ: {final_age:.1f}, DÃ¶nen Nihai GÃ¼ven: {final_confidence:.4f}")
        return final_age, final_confidence, pseudo_label_data_to_save

    def _calculate_confidence_with_clip(self, face_image, estimated_age):
        import time
        start_time = time.time()
        logger.info(f"[AGE_LOG] _calculate_confidence_with_clip baÅŸladÄ±. Gelen YaÅŸ: {estimated_age:.1f}, GÃ¶rÃ¼ntÃ¼ Shape: {face_image.shape}")
        if self.clip_model is None or face_image.size == 0:
            logger.warning("[AGE_LOG] CLIP modeli yok veya yÃ¼z gÃ¶rÃ¼ntÃ¼sÃ¼ geÃ§ersiz, varsayÄ±lan gÃ¼ven (0.5) dÃ¶nÃ¼lÃ¼yor.")
            return 0.5
        try:
            # GÃ¶rÃ¼ntÃ¼yÃ¼ RGB'ye dÃ¶nÃ¼ÅŸtÃ¼r ve PIL formatÄ±na Ã§evir
            rgb_image = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(rgb_image)
            
            # CLIP iÃ§in Ã¶n iÅŸleme
            preprocessed_image = self.clip_preprocess(pil_image).unsqueeze(0).to(self.clip_device)
            
            # DÄ°REKT YAÅ SORUSU: "this face is X years old"
            # Not: CLIP sayÄ±sal yaÅŸta sÄ±nÄ±rlÄ±; 18 eÅŸiÄŸinde (under18 vs adult) daha hassas olmasÄ± iÃ§in
            # karÅŸÄ±t prompt setini 17â€“21 bandÄ±na yakÄ±nlaÅŸtÄ±rÄ±yoruz ve ayrÄ±ca under18 vs adult promptlarÄ± ile
            # ek bir ayrÄ±m skoru logluyoruz.
            age = int(round(estimated_age))
            
            # Spesifik yaÅŸ sorusu
            target_prompt = f"this face is {age} years old"
            
            def _uniq_ints(values):
                out = []
                seen = set()
                for v in values:
                    try:
                        iv = int(v)
                    except Exception:
                        continue
                    if iv in seen:
                        continue
                    if iv < 1 or iv > 90:
                        continue
                    if iv == age:
                        continue
                    out.append(iv)
                    seen.add(iv)
                return out

            # KarÅŸÄ±t yaÅŸ sorularÄ± (farklÄ± yaÅŸ aralÄ±klarÄ±ndan)
            # 18 eÅŸiÄŸine yakÄ±n yaÅŸlarda ayrÄ±mÄ± gÃ¼Ã§lendirmek iÃ§in 17â€“21 bandÄ±nÄ± dahil et.
            if 13 <= age <= 22:
                opposing_ages = _uniq_ints(
                    [
                        age - 4,
                        age - 2,
                        17,
                        18,
                        19,
                        20,
                        21,
                        age + 2,
                        age + 4,
                        8,
                        30,
                        50,
                    ]
                )[:8]
            elif age < 10:
                opposing_ages = _uniq_ints([25, 45, 65, 16])  # Bebek/Ã§ocuk iÃ§in yetiÅŸkin yaÅŸlarÄ±
            elif age < 20:
                opposing_ages = _uniq_ints([5, 30, 50, 70])   # GenÃ§ iÃ§in diÄŸer yaÅŸlar
            elif age < 30:
                opposing_ages = _uniq_ints([8, 45, 65, 15])   # GenÃ§ yetiÅŸkin iÃ§in diÄŸer yaÅŸlar
            elif age < 50:
                opposing_ages = _uniq_ints([10, 20, 65, 75])  # Orta yaÅŸ iÃ§in diÄŸer yaÅŸlar
            else:
                opposing_ages = _uniq_ints([8, 18, 30, 45])   # YaÅŸlÄ± iÃ§in genÃ§ yaÅŸlar

            opposing_prompts = [f"this face is {opp_age} years old" for opp_age in opposing_ages]

            # Under18 vs Adult (18+) ayrÄ±mÄ± iÃ§in ek prompt seti (confidence doÄŸrulama iÃ§in)
            under18_prompts = [
                "this face is under 18 years old",
                "this person is a minor (under 18)",
                "a teenage person (under 18)",
            ]
            adult_prompts = [
                "this face is 18 years old or older",
                "this person is an adult (18 or older)",
                "an adult person (18+)",
            ]

            # TÃ¼m prompt'larÄ± birleÅŸtir (tek encode_text Ã§aÄŸrÄ±sÄ± iÃ§in)
            all_prompts = [target_prompt] + opposing_prompts + under18_prompts + adult_prompts
            
            # CLIP ile benzerlik hesapla
            with torch.no_grad():
                image_features = self.clip_model.encode_image(preprocessed_image)
                image_features /= image_features.norm(dim=-1, keepdim=True)
                
                text_inputs = self.tokenizer(all_prompts).to(self.clip_device)
                text_features = self.clip_model.encode_text(text_inputs)
                text_features /= text_features.norm(dim=-1, keepdim=True)
                
                # Benzerlik skorlarÄ±nÄ± al
                similarities = (100.0 * image_features @ text_features.T).squeeze(0).cpu().numpy()
            
            target_score = float(similarities[0])
            opposing_scores = similarities[1: 1 + len(opposing_prompts)]
            avg_opposing = float(np.mean(opposing_scores))
            max_opposing = float(np.max(opposing_scores))
            
            # MAXIMUM opposing score ile karÅŸÄ±laÅŸtÄ±r (daha hassas)
            score_diff = target_score - max_opposing
            
            # EÄŸer target score, max opposing'den dÃ¼ÅŸÃ¼kse net negatif gÃ¼ven
            if score_diff < 0:
                confidence_score = 0.1  # Minimum gÃ¼ven
            else:
                # Softmax-style confidence
                confidence_score = 1.0 / (1.0 + np.exp(-score_diff * 2))
                confidence_score = max(0.1, min(0.9, confidence_score))

            # Under18 vs Adult iÃ§in ek skor (log + 18 eÅŸiÄŸinde stabilizasyon)
            u_start = 1 + len(opposing_prompts)
            u_end = u_start + len(under18_prompts)
            a_start = u_end
            a_end = a_start + len(adult_prompts)

            under18_scores = similarities[u_start:u_end]
            adult_scores = similarities[a_start:a_end]
            under18_mean = float(np.mean(under18_scores))
            adult_mean = float(np.mean(adult_scores))
            under18_diff = under18_mean - adult_mean
            prob_under18 = float(1.0 / (1.0 + np.exp(-under18_diff * 0.8)))
            side_conf = prob_under18 if age < 18 else (1.0 - prob_under18)

            # 18 bandÄ±nda (13â€“22) confidence'i under18 ekseni ile harmanla
            if 13 <= age <= 22:
                confidence_score = (confidence_score * 0.5) + (side_conf * 0.5)
                confidence_score = max(0.1, min(0.9, float(confidence_score)))
            
            end_time = time.time()
            elapsed_time = end_time - start_time
            
            logger.info(f"[AGE_LOG] DÄ°REKT YAÅ SORUSU - Target YaÅŸ: {age}")
            logger.info(f"[AGE_LOG] Target Prompt: '{target_prompt}'")
            logger.info(f"[AGE_LOG] Opposing Prompts: {opposing_prompts}")
            logger.info(f"[AGE_LOG] Target Skor: {target_score:.4f}")
            logger.info(f"[AGE_LOG] Opposing Skorlar: {[f'{s:.4f}' for s in opposing_scores]}")
            logger.info(f"[AGE_LOG] Opposing Ort: {avg_opposing:.4f}, Max: {max_opposing:.4f}")
            logger.info(f"[AGE_LOG] Skor FarkÄ± (Target - Max): {score_diff:.4f}")
            logger.info(
                f"[AGE_LOG] Under18 vs Adult: under18_mean={under18_mean:.4f} adult_mean={adult_mean:.4f} "
                f"diff={under18_diff:.4f} prob_under18={prob_under18:.3f} side_conf={side_conf:.3f}"
            )
            logger.info(f"[AGE_LOG] Final GÃ¼ven: {confidence_score:.4f}")
            logger.info(f"[AGE_LOG] CLIP hesaplama sÃ¼resi: {elapsed_time:.3f} saniye")
            
            return confidence_score
            
        except Exception as e:
            end_time = time.time()
            elapsed_time = end_time - start_time
            logger.error(f"[AGE_LOG] CLIP ile gÃ¼ven skoru hesaplanÄ±rken hata: {str(e)} (SÃ¼re: {elapsed_time:.3f}s)")
            return 0.5 # Hata durumunda varsayÄ±lan gÃ¼ven

    def compute_face_encoding(self, face_image: np.ndarray):
        """
        Verilen yÃ¼z gÃ¶rÃ¼ntÃ¼sÃ¼nden embedding (vektÃ¶r) Ã§Ä±karÄ±r.
        Args:
            face_image: BGR (OpenCV) formatÄ±nda numpy array
        Returns:
            embedding: np.ndarray veya None
        """
        faces = self.model.get(face_image)
        if not faces:
            return None
        return faces[0].embedding

    def compare_faces(self, encoding1, encoding2, tolerance=0.6):
        """
        Ä°ki embedding (yÃ¼z vektÃ¶rÃ¼) arasÄ±ndaki benzerliÄŸi kontrol eder.
        Args:
            encoding1: np.ndarray
            encoding2: np.ndarray
            tolerance: float (daha dÃ¼ÅŸÃ¼k deÄŸer = daha sÄ±kÄ± eÅŸleÅŸme)
        Returns:
            bool: Benzerse True
        """
        if encoding1 is None or encoding2 is None:
            return False
        distance = np.linalg.norm(np.array(encoding1) - np.array(encoding2))
        return distance <= tolerance

    def get_faces(self, image: np.ndarray):
        # This method is not provided in the original file or the code block
        # It's assumed to exist as it's called in the estimate_age method
        pass

# KullanÄ±m Ã¶rneÄŸi:
# estimator = InsightFaceAgeEstimator()
# img = cv2.imread('face.jpg')
# age = estimator.estimate_age(img)
# print('Tahmini yaÅŸ:', age)

# Bu fonksiyonu analysis_service.py tarafÄ±ndan import edilebilmesi iÃ§in ekliyoruz.
def get_age_estimator():
    """InsightFaceAgeEstimator sÄ±nÄ±fÄ±ndan bir Ã¶rnek dÃ¶ndÃ¼rÃ¼r."""
    return InsightFaceAgeEstimator() 