# Model State File
# Bu dosya model aktivasyonlarÄ±nda gÃ¼ncellenir ve Flask debug mode tarafÄ±ndan izlenir
# Otomatik restart iÃ§in config.py tarafÄ±ndan import edilir

import threading
import time
from datetime import datetime
import weakref
import logging

logger = logging.getLogger(__name__)

# Thread-safe model state management
_state_lock = threading.Lock()

# Model instance cache for performance optimization
_model_instances = {}
_model_lock = threading.Lock()

MODEL_STATE = {
    'age': {
        'active_version': 1,  # En son versiyon aktif
        'last_activation': datetime.now().isoformat()
    },
    'content': {
        'active_version': None,
        'last_activation': None
    }
}

# Bu satÄ±r Flask'Ä±n dosya deÄŸiÅŸikliklerini algÄ±lamasÄ± iÃ§in
# Her model aktivasyonunda timestamp gÃ¼ncellenir
LAST_UPDATE = "2025-05-30T18:54:00.000000"

def update_model_state(model_type: str, version_id) -> None:
    """
    Thread-safe model state gÃ¼ncelleme.
    Args:
        model_type (str): Model tipi ('age', 'content', etc.).
        version_id: Versiyon ID'si (int, str, or None).
    Returns:
        None
    """
    global MODEL_STATE, LAST_UPDATE
    
    with _state_lock:
        if model_type not in MODEL_STATE:
            MODEL_STATE[model_type] = {}
        
        MODEL_STATE[model_type]['active_version'] = version_id
        MODEL_STATE[model_type]['last_activation'] = datetime.now().isoformat()
        
        # Flask dosya deÄŸiÅŸiklik algÄ±lamasÄ± iÃ§in timestamp gÃ¼ncelle
        LAST_UPDATE = datetime.now().isoformat()

def get_model_state(model_type=None):
    """
    Thread-safe model state okuma
    
    Args:
        model_type (str, optional): Belirli model tipi, None ise tÃ¼mÃ¼
        
    Returns:
        dict: Model state bilgisi
    """
    with _state_lock:
        if model_type:
            return MODEL_STATE.get(model_type, {}).copy()
        return MODEL_STATE.copy()

def reset_model_state():
    """
    TÃ¼m model state'ini sÄ±fÄ±rla
    """
    global MODEL_STATE, LAST_UPDATE
    
    with _state_lock:
        MODEL_STATE = {
            'age': {'active_version': 0, 'last_activation': None},
            'content': {'active_version': None, 'last_activation': None}
        }
        LAST_UPDATE = datetime.now().isoformat()

def get_age_estimator():
    """
    Performance-optimized thread-safe singleton InsightFaceAgeEstimator
    
    Returns:
        InsightFaceAgeEstimator: Cached model instance
    """
    cache_key = 'age_estimator'
    
    # Thread-safe cache kontrolÃ¼
    with _model_lock:
        if cache_key in _model_instances:
            instance = _model_instances[cache_key]
            if instance is not None:
                logger.debug("Age estimator cache'den kullanÄ±lÄ±yor")
                return instance
    
    # Cache miss - yeni instance oluÅŸtur
    try:
        from app.ai.insightface_age_estimator import InsightFaceAgeEstimator
        logger.info("Yeni InsightFaceAgeEstimator instance oluÅŸturuluyor...")
        
        start_time = time.time()
        estimator = InsightFaceAgeEstimator()  # CLIP shared olarak inject edilecek
        load_time = time.time() - start_time
        
        # Thread-safe cache'e kaydet
        with _model_lock:
            _model_instances[cache_key] = estimator
            
        logger.info(f"InsightFaceAgeEstimator cache'e kaydedildi ({load_time:.2f}s)")
        return estimator
        
    except Exception as e:
        logger.error(f"InsightFaceAgeEstimator yÃ¼kleme hatasÄ±: {e}")
        raise

def get_content_analyzer():
    """
    Performance-optimized thread-safe singleton ContentAnalyzer
    
    Returns:
        ContentAnalyzer: Cached model instance
    """
    cache_key = 'content_analyzer'
    
    # Thread-safe cache kontrolÃ¼
    with _model_lock:
        if cache_key in _model_instances:
            instance = _model_instances[cache_key]
            if instance is not None and hasattr(instance, 'initialized') and instance.initialized:
                logger.debug("Content analyzer cache'den kullanÄ±lÄ±yor")
                return instance
    
    # Cache miss - yeni instance oluÅŸtur
    try:
        from app.ai.content_analyzer import ContentAnalyzer
        logger.info("Yeni ContentAnalyzer instance oluÅŸturuluyor...")
        
        start_time = time.time()
        analyzer = ContentAnalyzer()
        load_time = time.time() - start_time
        
        if analyzer.initialized:
            # Thread-safe cache'e kaydet
            with _model_lock:
                _model_instances[cache_key] = analyzer
                
            logger.info(f"ContentAnalyzer cache'e kaydedildi ({load_time:.2f}s)")
            return analyzer
        else:
            raise RuntimeError("ContentAnalyzer initialization failed")
            
    except Exception as e:
        logger.error(f"ContentAnalyzer yÃ¼kleme hatasÄ±: {e}")
        raise

def clear_model_cache(model_type=None):
    """
    Model cache'ini temizle - memory management iÃ§in
    
    Args:
        model_type (str, optional): Temizlenecek model tipi ('age', 'content'), None ise tÃ¼mÃ¼
    """
    with _model_lock:
        if model_type == 'age':
            if 'age_estimator' in _model_instances:
                instance = _model_instances['age_estimator']
                if hasattr(instance, 'cleanup_models'):
                    instance.cleanup_models()
                del _model_instances['age_estimator']
                logger.info("Age estimator cache temizlendi")
                
        elif model_type == 'content':
            if 'content_analyzer' in _model_instances:
                instance = _model_instances['content_analyzer']
                if hasattr(instance, 'cleanup_models'):
                    instance.cleanup_models()
                del _model_instances['content_analyzer']
                logger.info("Content analyzer cache temizlendi")
                
        else:
            # TÃ¼m cache'i temizle
            for key, instance in _model_instances.items():
                if hasattr(instance, 'cleanup_models'):
                    instance.cleanup_models()
            _model_instances.clear()
            logger.info("TÃ¼m model cache temizlendi")

def get_cache_stats():
    """
    Model cache istatistiklerini dÃ¶ndÃ¼r
    
    Returns:
        dict: Cache istatistikleri
    """
    with _model_lock:
        stats = {
            'cached_models': list(_model_instances.keys()),
            'cache_size': len(_model_instances),
            'memory_usage': {}
        }
        
        for key, instance in _model_instances.items():
            stats['memory_usage'][key] = {
                'type': type(instance).__name__,
                'initialized': getattr(instance, 'initialized', 'N/A')
            }
            
        return stats

def set_age_model_version(version_id):
    """
    YaÅŸ modeli aktif versiyonunu ayarla
    
    Args:
        version_id: Versiyon ID'si (int, 0 = base model)
    """
    update_model_state('age', version_id)
    logger.info(f"Age model version set to: {version_id}")

def set_content_model_version(version_id):
    """
    Ä°Ã§erik modeli aktif versiyonunu ayarla
    
    Args:
        version_id: Versiyon ID'si (int, 0 = base model) 
    """
    update_model_state('content', version_id)
    logger.info(f"Content model version set to: {version_id}")

def update_model_state_file(model_type, version_id):
    """
    Model state dosyasÄ±nÄ± gÃ¼ncelle (backward compatibility iÃ§in)
    
    Args:
        model_type (str): Model tipi ('age' veya 'content')
        version_id: Versiyon ID'si
    """
    update_model_state(model_type, version_id)
    logger.info(f"Model state file updated: {model_type} -> version {version_id}")


def reset_model_cache():
    """
    Model cache'ini temizler. Model aktivasyonundan sonra Ã§aÄŸrÄ±lÄ±r.
    Bu sayede in-memory model instance'larÄ± yeniden yÃ¼klenir.
    """
    global _model_instances
    
    with _model_lock:
        old_count = len(_model_instances)
        _model_instances.clear()
        logger.info(f"ğŸ”„ Model cache temizlendi ({old_count} instance kaldÄ±rÄ±ldÄ±)")
        
    # Force garbage collection for cached models
    import gc
    gc.collect()